# app.py â€” Funky Brain LIVE (Stable + Cleaner + Model Toggle)
# - ÙŠÙ‚Ø±Ø£ Ù…Ù† data/combined_spins.csv Ø£Ùˆ Ù…Ù† Ø±ÙØ¹ Ù…Ù„Ù / Google Sheets
# - Ø²Ø±: ØªÙ†Ø¸ÙŠÙ Ù…Ù„Ù Ø®Ø§Ù… casinoscores ÙˆØ¥Ø¶Ø§ÙØªÙ‡ Ø¥Ù„Ù‰ combined_spins.csv
# - Ù†Ù…ÙˆØ°Ø¬ Recency+Softmax Ù…Ø¹ Bonus boost + (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ¹Ù„Ù‘Ù… Ù…Ù† pkl
# - ØªØ¨ÙˆÙŠØ¨Ø§Øª: Tiles / Board + 10 / Table / Falcon Eye
# - ØªØ­Ø°ÙŠØ± Ø¹ÙŠÙ† Ø§Ù„ØµÙ‚Ø±: ØªÙƒØ±Ø§Ø± "1" â‰¥ 3 Ù…Ø±Ø§Øª ÙÙŠ 10 / Ø³ÙŠØ·Ø±Ø© Ù…Ø­ØªÙ…Ù„Ø© Ø®Ù„Ø§Ù„ 15
# - Ø¥ØµÙ„Ø§Ø­Ø§Øª: parsing Ù„Ù„ØªÙˆØ§Ø±ÙŠØ®ØŒ ÙØ±Ø² Ø¢Ù…Ù†ØŒ UNKNOWN+1X => "1"ØŒ Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¯Ø§Ø¦Ù…Ù‹Ø§

import os
import re
import math
import json
import pandas as pd
import numpy as np
import streamlit as st
from datetime import datetime

# ===== Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯ÙˆØ§Ù„Ù‘Ùƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¥Ù† ÙˆÙØ¬Ø¯Øª (Ù„Ø§ Ù†ÙƒØ³Ø± Ø´ÙŠØ¡) =====
_HAS_CORE = False
try:
    from funkybrain_core import normalize_df, compute_probs, board_model
    _HAS_CORE = True
except Exception:
    _HAS_CORE = False

# ------------------------ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø© ------------------------
st.set_page_config(page_title="Funky Brain LIVE", layout="wide")
st.title("ğŸ§  Funky Brain â€” LIVE")

# Ù…Ø³Ø§Ø±Ø§Øª
DATA_DIR = "data"
MODELS_DIR = "models"
REPO_COMBINED_PATH = os.path.join(DATA_DIR, "combined_spins.csv")

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)

# Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª
COLORS = {
    "ONE": "#F4D36B", "BAR": "#5AA64F",
    "ORANGE": "#E7903C", "PINK": "#C85C8E", "PURPLE": "#9A5BC2",
    "STAYINALIVE": "#4FC3D9", "DISCO": "#314E96", "DISCO_VIP": "#B03232",
}
BONUS_SEGMENTS = {"DISCO","STAYINALIVE","DISCO_VIP","BAR"}
ALL_SEGMENTS = {
    "1","BAR","P","L","A","Y","F","U","N","K","Y","T","I","M","E","DISCO","STAYINALIVE","DISCO_VIP","UNKNOWN"
}
ORDER = ["1","BAR","P","L","A","Y","F","U","N","K","Y","T","I","M","E","DISCO","STAYINALIVE","DISCO_VIP"]

# Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª
TILE_H=96; TILE_TXT=38; TILE_SUB=13
TILE_H_SMALL=84; TILE_TXT_SMALL=32; TILE_SUB_SMALL=12
TILE_TXT_BONUS=20

# ------------------------ ÙˆØ¸Ø§Ø¦Ù UI Ù…Ø³Ø§Ø¹Ø¯Ø© ------------------------
def pct(x: float) -> str:
    try:
        return f"{float(x)*100:.1f}%"
    except Exception:
        return "0.0%"

def p_at_least_once(p: float, n: int) -> float:
    return 1.0 - (1.0 - float(p))**int(n)

def exp_count(p: float, n: int) -> float:
    return float(n) * float(p)

def letter_color(letter: str) -> str:
    if letter in {"1","ONE"}: return COLORS["ONE"]
    if letter=="BAR": return COLORS["BAR"]
    if letter in {"P","L","A","Y"}: return COLORS["ORANGE"]
    if letter in {"F","U","N","K","Y","Y2"}: return COLORS["PINK"]
    if letter in {"T","I","M","E"}: return COLORS["PURPLE"]
    if letter=="STAYINALIVE": return COLORS["STAYINALIVE"]
    if letter=="DISCO": return COLORS["DISCO"]
    if letter=="DISCO_VIP": return COLORS["DISCO_VIP"]
    return "#444"

def display_tile(label, subtext, bg, height=TILE_H, radius=16, txt_size=TILE_TXT, sub_size=TILE_SUB):
    st.markdown(
        f"""
        <div style="background:{bg};color:white;border-radius:{radius}px;height:{height}px;
                    display:flex;flex-direction:column;align-items:center;justify-content:center;font-weight:700;">
            <div style="font-size:{txt_size}px;line-height:1">{label if label!='Y2' else 'Y'}</div>
            <div style="font-size:{sub_size}px;opacity:.95;margin-top:2px">{subtext}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

def section_header(title):
    st.markdown(
        f"<div style='font-size:20px;font-weight:700;margin:6px 0 10px'>{title}</div>",
        unsafe_allow_html=True,
    )

# ---------- Ù…Ù†Ø¸Ù‘Ù Ù‚ÙŠØ§Ø³ÙŠ Ù„Ø¬Ø¯ÙˆÙ„ Ù†Ø¸ÙŠÙ ----------
def clean_df(df: pd.DataFrame) -> pd.DataFrame:
    needed = ["ts","segment","multiplier"]
    df = df.copy()

    # Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ù„Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¥Ù† ÙƒØ§Ù†Øª Ø¨Ø£Ø³Ù…Ø§Ø¡ Ù…Ø®ØªÙ„ÙØ©
    colmap = {c.lower(): c for c in df.columns}
    ts_col = colmap.get("ts") or colmap.get("time") or colmap.get("timestamp") or colmap.get("date")
    seg_col = colmap.get("segment") or colmap.get("tile") or colmap.get("symbol")
    mul_col = colmap.get("multiplier") or colmap.get("multi") or colmap.get("x") or colmap.get("payout")

    if ts_col is None or seg_col is None or mul_col is None:
        # Ù„Ùˆ ÙØ´Ù„ØŒ Ø¬Ø±Ø¨ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø¨Ø¯ÙˆÙ† Ø±Ø¤ÙˆØ³ (Ù…Ù„ÙØ§Øª Ø³ÙŠØ¦Ø©)
        try:
            tmp = pd.read_csv(df.to_csv(index=False), header=None)
            tmp.columns = ["ts","segment","multiplier"][:tmp.shape[1]] + [f"c{i}" for i in range(3, tmp.shape[1])]
            df = tmp
            ts_col, seg_col, mul_col = "ts","segment","multiplier"
        except Exception:
            raise ValueError("Column missing: ts/segment/multiplier")

    # ØªØ­ÙˆÙŠÙ„
    out = pd.DataFrame({
        "ts": pd.to_datetime(df[ts_col], errors="coerce"),
        "segment": df[seg_col].astype(str).str.strip().str.upper(),
        "multiplier": df[mul_col].astype(str),
    })

    # multiplier -> "12X"
    out["multiplier"] = (
        out["multiplier"].str.extract(r"(\d+)\s*[xX]?", expand=False)
        .fillna("1").astype(int).astype(str) + "X"
    )

    # UNKNOWN + 1X => "1"
    mask_one = (out["segment"].isin(["UNKNOWN","N/A","NULL","-",""])) & (out["multiplier"].eq("1X"))
    out.loc[mask_one, "segment"] = "1"

    allowed = set(ALL_SEGMENTS)
    out.loc[~out["segment"].isin(allowed), "segment"] = "UNKNOWN"

    out = out.dropna(subset=["ts"]).sort_values("ts").reset_index(drop=True)
    return out[needed]

# ---------- ØªÙ†Ø¸ÙŠÙ Ù…Ù„Ù casinoscores Ø§Ù„Ø®Ø§Ù… (Ø±ÙˆØ§Ø¨Ø· ØµÙˆØ±) ----------
NAME2SEG = {
    "1": "1",
    "bar": "BAR", "barstatpin": "BAR", "barstat": "BAR",
    "discovip": "DISCO_VIP", "disco_vip": "DISCO_VIP", "vipdisco": "DISCO_VIP",
    "disco": "DISCO",
    "stayinalive": "STAYINALIVE", "stayin_alive": "STAYINALIVE", "stayin": "STAYINALIVE",
    "p":"P","l":"L","a":"A","y":"Y","f":"F","u":"U","n":"N","k":"K","t":"T","i":"I","m":"M","e":"E",
}
IMG_PATTERNS = [
    re.compile(r"/funky[-_]?time/([a-z0-9_]+)\.png", re.I),
    re.compile(r"/(barstatpin|barstat|bar|discovip|disco|stayinalive|stayin_alive|stayin|[playfuknytime1])\.png", re.I),
    re.compile(r"/([playfuknytime1])\.png", re.I),
]

def _guess_segment_from_text(text: str) -> str:
    t = str(text)
    for pat in IMG_PATTERNS:
        m = pat.search(t)
        if m:
            key = m.group(1).lower().strip().replace(" ", "")
            return NAME2SEG.get(key, "UNKNOWN")
    return "UNKNOWN"

def clean_raw_casinoscores(df_raw: pd.DataFrame) -> pd.DataFrame:
    """ÙŠØ¯Ø¹Ù… Ù…Ù„ÙØ§Øª Ø¨Ù„Ø§ Ø±Ø¤ÙˆØ³ØŒ Ø£Ùˆ Ø±Ø¤ÙˆØ³ ØºÙŠØ± Ù…ÙˆØ­Ù‘Ø¯Ø©ØŒ Ø£Ùˆ Ø£Ø¹Ù…Ø¯Ø© Ù†ØµÙŠØ© ÙÙ‚Ø·."""
    if df_raw is None or df_raw.empty:
        return pd.DataFrame(columns=["ts","segment","multiplier"])

    # 1) ØªØ­Ø¯ÙŠØ¯ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø²Ù…Ù† (Ø£Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ­ÙˆÙŠÙ„)
    ts_col = None
    best_nonnull = -1
    for c in df_raw.columns:
        try:
            cand = pd.to_datetime(df_raw[c], errors="coerce")
            nn = cand.notna().mean()
            if nn >= 0.30 and nn > best_nonnull:
                ts_col = c
                best_nonnull = nn
        except Exception:
            pass
    if ts_col is None:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ø®ÙŠØ±Ø©: Ø¨Ø¯ÙˆÙ† Ø±Ø¤ÙˆØ³
        try:
            tmp = pd.read_csv(df_raw.to_csv(index=False), header=None)
            return clean_raw_casinoscores(tmp)
        except Exception:
            raise ValueError("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ ØªØ§Ø±ÙŠØ®/ÙˆÙ‚Øª Ù…ÙÙ‡ÙˆÙ… (ts/time/timestamp/date).")

    # 2) Ø§Ø³ØªØ®Ø±Ø§Ø¬ segment & multiplier Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø¬Ø§ÙˆØ±Ø© (Ø§Ù„Ø±ÙˆØ§Ø¨Ø·â€¦)
    text_cols = [c for c in df_raw.columns if c != ts_col]
    if not text_cols:
        text_cols = [ts_col]

    segs, mults = [], []
    for _, row in df_raw.iterrows():
        blob = " ".join(str(row[c]) for c in text_cols)
        seg = _guess_segment_from_text(blob)

        # multiplier
        mul = None
        m = re.search(r"(\d+)\s*[xX]\b", blob)
        if m:
            mul = m.group(1) + "X"

        # fallback Ù…Ù† Ø£Ø¹Ù…Ø¯Ø© Ù…Ø³Ù…Ø§Ø©
        if seg == "UNKNOWN" and "segment" in df_raw.columns:
            seg = str(row.get("segment","UNKNOWN")).strip().upper() or "UNKNOWN"
        if not mul and "multiplier" in df_raw.columns:
            mv = str(row.get("multiplier","")).strip()
            m2 = re.search(r"(\d+)\s*[xX]?", mv)
            mul = (m2.group(1)+"X") if m2 else None

        # Ù‚Ø§Ø¹Ø¯Ø© Ø®Ø§ØµØ©: UNKNOWN + 1X => "1"
        if (seg == "UNKNOWN") and (mul or "").upper() == "1X":
            seg = "1"

        segs.append(seg)
        mults.append((mul or "1X").upper())

    out = pd.DataFrame({
        "ts": pd.to_datetime(df_raw[ts_col], errors="coerce"),
        "segment": pd.Series(segs, dtype="string").str.upper().str.replace(r"\s+","", regex=True),
        "multiplier": pd.Series(mults, dtype="string").str.upper(),
    })
    allowed = set(ALL_SEGMENTS)
    out.loc[~out["segment"].isin(allowed), "segment"] = "UNKNOWN"
    out["multiplier"] = out["multiplier"].str.extract(r"(\d+)", expand=False)\
                                        .fillna("1").astype(int).astype(str) + "X"
    out = out.dropna(subset=["ts"]).sort_values("ts").reset_index(drop=True)
    return out[["ts","segment","multiplier"]]

# ---------- Ø¯Ù…Ø¬ Ø¥Ù„Ù‰ combined_spins.csv ----------
def append_to_combined(df_new: pd.DataFrame, path=REPO_COMBINED_PATH) -> int:
    try:
        if os.path.exists(path):
            old = pd.read_csv(path)
            # ØªÙˆØ­ÙŠØ¯ Ù‚Ø¨Ù„ Ø§Ù„Ø¯Ù…Ø¬
            old = clean_df(old)
            big = pd.concat([old, df_new], ignore_index=True)
        else:
            big = df_new.copy()
        big = clean_df(big)
        big = big.drop_duplicates(subset=["ts","segment","multiplier"]).sort_values("ts")
        big.to_csv(path, index=False, encoding="utf-8")
        return len(big)
    except Exception as e:
        raise RuntimeError(f"ÙØ´Ù„ Ø§Ù„Ø¯Ù…Ø¬/Ø§Ù„Ø­ÙØ¸: {e}")

# -------- Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª: Recency + Softmax + Bonus boost --------
def recency_softmax_probs(df, horizon=10, temperature=1.6, decay_half_life=60, bonus_boost=1.15):
    try:
        dfx = df.copy()
        segs = list(ALL_SEGMENTS - {"UNKNOWN"})  # Ù†ØªØ¬Ø§Ù‡Ù„ UNKNOWN ÙÙŠ Ø§Ù„ØªÙ‚Ø¯ÙŠØ±
        n = len(dfx)

        if n == 0:
            vec = np.ones(len(segs), dtype=float)
        else:
            ages = np.arange(n, 0, -1)               # Ø§Ù„Ø£Ø­Ø¯Ø« Ø¹Ù…Ø±Ù‡ 1
            half = max(int(decay_half_life), 1)
            w = np.power(0.5, (ages-1)/half)         # ÙˆØ²Ù† Ø£Ø³ÙŠ
            w = w / w.sum()

            counts = {s: 0.0 for s in segs}
            for seg, wt in zip(dfx["segment"], w):
                if seg in counts: counts[seg] += wt
            vec = np.array([counts[s] for s in segs], dtype=float)

        for i, s in enumerate(segs):
            if s in BONUS_SEGMENTS:
                vec[i] *= float(bonus_boost)

        if vec.sum() <= 0: vec[:] = 1.0
        x = vec / (vec.std() + 1e-9)
        x = x / max(float(temperature), 1e-6)
        z = np.exp(x - x.max())
        p_next = z / z.sum()

        probs = dict(zip(segs, p_next))
        p_in10 = {s: p_at_least_once(probs[s], horizon) for s in segs}
        return probs, p_in10
    except Exception:
        counts = df["segment"].value_counts()
        segs = list(ALL_SEGMENTS - {"UNKNOWN"})
        vec = np.array([counts.get(s, 0) for s in segs], dtype=float)
        if vec.sum() == 0: vec[:] = 1.0
        z = np.exp((vec - vec.mean()) / (vec.std() + 1e-6))
        p = z / z.sum()
        probs = dict(zip(segs, p))
        p_in10 = {s: p_at_least_once(probs[s], horizon) for s in segs}
        return probs, p_in10

def get_probs_recency(df, horizon=10, temperature=1.6, decay_half_life=60, bonus_boost=1.15):
    if _HAS_CORE:
        try:
            dfn = clean_df(df)
            comp = compute_probs(dfn, horizon=horizon)
            p_next = comp.get("p_next", {})
            p_in10 = comp.get("p_in10", {})
            if len(p_next) == 0 or len(p_in10) == 0:
                raise ValueError("Empty core probs")
            return p_next, p_in10
        except Exception:
            pass
    return recency_softmax_probs(df, horizon, temperature, decay_half_life, bonus_boost)

# ------------------------ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©: Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ø£ÙˆÙ„Ù‹Ø§ (Ø§Ù„ØªØ¯Ø±ÙŠØ¨/Ø§Ù„Ù†Ù…ÙˆØ°Ø¬) ------------------------
with st.sidebar:
    st.subheader("ğŸ¤– Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ¹Ù„Ù‘Ù… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    use_learned = st.toggle("Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ØªØ¹Ù„Ù‘Ù… Ø¥Ù† ÙˆØ¬Ø¯", value=False)
    model_path = st.text_input("Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", value=os.path.join(MODELS_DIR, "pattern_model.pkl"))

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ù„Ùˆ Ù…ÙØ¹Ù‘Ù„)
    loaded_model = None
    if use_learned and os.path.exists(model_path):
        try:
            import pickle
            with open(model_path, "rb") as f:
                loaded_model = pickle.load(f)
            st.success("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
            if "meta" in loaded_model:
                with st.expander("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (meta)"):
                    st.code(json.dumps(loaded_model["meta"], ensure_ascii=False, indent=2))
        except Exception as e:
            st.error(f"ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")

    st.markdown("---")
    st.subheader("ğŸ§ª ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    save_model_path = st.text_input("Ù…Ø³Ø§Ø± Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", value=os.path.join(MODELS_DIR,"pattern_model.pkl"))
    with st.expander("Ù…Ù„Ø®Øµ Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ¯Ø± Ø£Ø³ÙÙ„)"):
        st.caption("Ø¨Ø¹Ø¯ Ø§Ø®ØªÙŠØ§Ø± Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„Ø£Ø³ÙÙ„ Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø³Ø±ÙŠØ¹ Ù‡Ù†Ø§.")
    train_now_btn = st.button("ğŸ’¾ Ø¯Ø±Ù‘ÙØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¢Ù†", use_container_width=True, key="train_btn_top")

# ------------------------ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª + Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ ------------------------
with st.sidebar:
    st.markdown("---")
    st.subheader("ğŸ“¥ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    # Ø²Ø± ØªÙ†Ø¸ÙŠÙ/Ø¥Ø¶Ø§ÙØ© Ù„Ù…Ù„Ù Ø®Ø§Ù… casinoscores
    st.caption("Ù„Ùˆ Ù„Ø¯ÙŠÙƒ Ù…Ù„Ù Ø®Ø§Ù… Ù…Ù† Instant Data Scraper (ÙŠØ­ØªÙˆÙŠ Ø±ÙˆØ§Ø¨Ø· ØµÙˆØ±)ØŒ Ù†Ø¸Ù‘ÙÙÙ‡ ÙˆØ£Ø¶ÙÙ‡ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø®Ø²ÙˆÙ†:")
    raw_file = st.file_uploader("Ù…Ù„Ù Ø®Ø§Ù… (CSV/XLSX/XLS)", type=["csv","xlsx","xls"], key="raw_uploader")

    if raw_file is not None:
        if st.button("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ + Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ combined_spins.csv", use_container_width=True):
            try:
                if raw_file.name.lower().endswith(".csv"):
                    df_raw = pd.read_csv(raw_file, header=0, engine="python", encoding_errors="ignore")
                else:
                    df_raw = pd.read_excel(raw_file)

                df_clean = clean_raw_casinoscores(df_raw)
                total_rows = append_to_combined(df_clean, REPO_COMBINED_PATH)
                st.success(f"âœ… ØªÙ… Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙˆØ§Ù„Ø¥Ø¶Ø§ÙØ© ({len(df_clean)} ØµÙÙ‹Ø§). Ø§Ù„Ø­Ø¬Ù… Ø§Ù„ÙƒÙ„ÙŠ Ø§Ù„Ø¢Ù†: {total_rows} ØµÙÙ‹Ø§.")
                st.dataframe(df_clean.tail(20), use_container_width=True)
            except Exception as e:
                st.error(f"âŒ ÙØ´Ù„ ØªÙ†Ø¸ÙŠÙ/Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø®Ø§Ù…: {e}")

    use_repo_combined = st.toggle("Ø§Ø³ØªØ®Ø¯Ù… Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ data/combined_spins.csv", value=True)
    sheet_url = st.text_input("Ø±Ø§Ø¨Ø· Google Sheets (Ù…ÙØ¶Ù‘Ù„ CSV export)", value="")
    upload = st.file_uploader("â€¦Ø£Ùˆ Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV/Excel Ù†Ø¸ÙŠÙ", type=["csv","xlsx","xls"], key="clean_uploader")

# ---------- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (repo / upload / sheets) ----------
@st.cache_data(show_spinner=False)
def load_data(file, sheet_url, window, use_repo_file=False, repo_path=REPO_COMBINED_PATH):
    df = None
    # Ù…Ù† Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
    if use_repo_file and os.path.exists(repo_path):
        try:
            df = pd.read_csv(repo_path)
        except Exception as e:
            st.warning(f"ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© {repo_path}: {e}")
    # Ù…Ù„Ù Ù…Ø±ÙÙˆØ¹
    if df is None and file is not None:
        try:
            if file.name.lower().endswith(".csv"):
                df = pd.read_csv(file, engine="python", encoding_errors="ignore")
            else:
                df = pd.read_excel(file)
        except Exception as e:
            st.error(f"ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
            return pd.DataFrame(columns=["ts","segment","multiplier"])
    # Google Sheets -> CSV
    if df is None and sheet_url:
        url = sheet_url.strip()
        if "docs.google.com/spreadsheets" in url and "export?format=csv" not in url:
            try: gid = url.split("gid=")[-1]
            except Exception: gid = "0"
            doc_id = url.split("/d/")[1].split("/")[0]
            url = f"https://docs.google.com/spreadsheets/d/{doc_id}/export?format=csv&gid={gid}"
        try:
            df = pd.read_csv(url)
        except Exception as e:
            st.error(f"ØªØ¹Ø°Ù‘Ø± ØªØ­Ù…ÙŠÙ„ Google Sheets: {e}")
            return pd.DataFrame(columns=["ts","segment","multiplier"])

    if df is None:
        return pd.DataFrame(columns=["ts","segment","multiplier"])

    try:
        df = clean_df(df)
    except Exception as e:
        st.error(f"ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ØºÙŠØ± ØµØ§Ù„Ø­: {e}")
        return pd.DataFrame(columns=["ts","segment","multiplier"])

    if len(df) > window:
        df = df.tail(window).copy()

    return df.reset_index(drop=True)

# ------------------------ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ------------------------
with st.sidebar:
    st.markdown("---")
    st.subheader("ğŸ›ï¸ Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤ (Recency/Softmax)")
    window = st.slider("Window size (spins)", 50, 300, 120, step=10)
    horizon = st.slider("ØªÙˆÙ‚Ø¹ Ø¹Ù„Ù‰ ÙƒÙ… Ø¬ÙˆÙ„Ø©ØŸ", 5, 20, 10, step=1)
    temperature = st.slider("Temperature (ØªØ±ÙƒÙŠØ² Ø§Ù„Ø³ÙˆÙØª-Ù…Ø§ÙƒØ³)", 1.0, 2.5, 1.6, 0.1)
    decay_half_life = st.slider("Half-life (ØªØ±Ø¬ÙŠØ­ Ø§Ù„Ø­Ø¯Ø§Ø«Ø©)", 20, 120, 60, 5)
    bonus_boost = st.slider("ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø¨ÙˆÙ†Øµ", 1.00, 1.40, 1.15, 0.05)

# Ø­Ù…Ù‘Ù„ Ø§Ù„Ø¯Ø§ØªØ§
df = load_data(upload, sheet_url, window, use_repo_file=use_repo_combined, repo_path=REPO_COMBINED_PATH)

# Ù…Ù„Ø®Øµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Ø§Ù„Ø°ÙŠ ÙˆÙØ¶Ø¹ Ø³Ø§Ø¨Ù‚Ù‹Ø§) ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ df
with st.sidebar:
    with st.expander("Ù…Ù„Ø®Øµ Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨", expanded=False):
        st.write(f"Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ØªØ§Ø­Ø©: **{len(df)}**")
        if not df.empty:
            st.dataframe(df.tail(10), use_container_width=True)

# ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ùˆ Ø¶ØºØ· Ø§Ù„Ø²Ø±
if train_now_btn:
    with st.sidebar:
        if df.empty:
            st.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨.")
        else:
            try:
                import pickle
                # Ù†Ø³ØªØ®Ø¯Ù… Ù†ÙØ³ Ù…Ù†Ø·Ù‚ Ø§Ù„Ù€ recency Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªØ·Ø§Ø¨Ù‚
                p_next_learned, _ = recency_softmax_probs(
                    df,
                    horizon=horizon,
                    temperature=temperature,
                    decay_half_life=decay_half_life,
                    bonus_boost=bonus_boost,
                )
                model = {
                    "type": "recency_softmax",
                    "p_next": p_next_learned,
                    "meta": {
                        "horizon": horizon,
                        "temperature": temperature,
                        "half_life": decay_half_life,
                        "bonus_boost": bonus_boost,
                        "trained_on_rows": int(len(df)),
                        "trained_at": datetime.utcnow().isoformat() + "Z",
                    },
                }
                with open(save_model_path, "wb") as f:
                    pickle.dump(model, f)
                st.success(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {save_model_path}")
                with open(save_model_path, "rb") as fh:
                    st.download_button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", fh.read(), file_name="pattern_model.pkl",
                                       mime="application/octet-stream", use_container_width=True)
            except Exception as e:
                st.error(f"ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")

# Ø¥Ù† Ù„Ù… ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ù†Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© ÙˆÙ†ÙƒÙ…Ù„ (Ù„Ø§ Ù†ÙˆÙ‚Ù Ø§Ù„ØµÙØ­Ø© ÙƒÙŠ ØªØ¨Ù‚Ù‰ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø¸Ø§Ù‡Ø±Ø©)
if df.empty:
    st.info("Ø£Ø¶Ù Ù…ØµØ¯Ø± Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­ ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: ts, segment, multiplier")

# ------------------------ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª ------------------------
if not df.empty:
    if loaded_model and use_learned and "p_next" in loaded_model:
        # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ØªØ¹Ù„Ù…
        p_next = {k: float(v) for k, v in loaded_model["p_next"].items() if k in ALL_SEGMENTS and k != "UNKNOWN"}
        # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ·Ø¨ÙŠØ¹ ØªØ­Ø³Ù‘Ø¨Ù‹Ø§
        s = sum(p_next.values()) or 1.0
        for k in p_next: p_next[k] /= s
        p_in10 = {s: p_at_least_once(p_next.get(s,0.0), 10) for s in p_next}
        source_label = "learned model"
    else:
        p_next, p_in10 = get_probs_recency(
            df, horizon=horizon, temperature=temperature,
            decay_half_life=decay_half_life, bonus_boost=bonus_boost
        )
        source_label = "recency"
else:
    p_next, p_in10 = {}, {}
    source_label = "none"

st.caption(f"Source of probabilities: {source_label}")

# ------------------------ Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª ------------------------
tab_tiles, tab_board, tab_table, tab_falcon = st.tabs(
    ["ğŸ›ï¸ Tiles", "ğŸ¯ Board + 10 Spins", "ğŸ“Š Table", "ğŸ¦… Falcon Eye"]
)

# ========== ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª ==========
with tab_tiles:
    section_header("Ù„ÙˆØ­Ø© Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª (Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØµØµØ©)")
    c1, c2, _, _ = st.columns([1.2, 1.2, 0.1, 0.1])
    with c1:
        display_tile("1", f"P(next) {pct(p_next.get('1', 0))}", letter_color("1"))
    with c2:
        display_tile("BAR", f"P(next) {pct(p_next.get('BAR', 0))}", letter_color("BAR"), txt_size=34)

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(4)
    for i, L in enumerate(["P","L","A","Y"]):
        with cols[i]:
            display_tile(L, f"P(next) {pct(p_next.get(L, 0))}", letter_color(L))

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(5)
    for i, L in enumerate(["F","U","N","K","Y"]):
        with cols[i]:
            display_tile(L, f"P(next) {pct(p_next.get(L, 0))}", letter_color(L if L!="Y" else "Y2"))

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(4)
    for i, L in enumerate(["T","I","M","E"]):
        with cols[i]:
            display_tile(L, f"P(next) {pct(p_next.get(L, 0))}", letter_color(L))

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(3)
    for i, B in enumerate(["DISCO","STAYINALIVE","DISCO_VIP"]):
        label = "VIP DISCO" if B=="DISCO_VIP" else ("STAYIN'ALIVE" if B=="STAYINALIVE" else "DISCO")
        with cols[i]:
            display_tile(label, f"P(next) {pct(p_next.get(B, 0))}", letter_color(B),
                         height=TILE_H, txt_size=TILE_TXT_BONUS)

# ========== ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ù„ÙˆØ­Ø© + 10 ==========
with tab_board:
    section_header("Ù„ÙˆØ­Ø© Ø§Ù„Ø±Ù‡Ø§Ù† + ØªÙˆÙ‚Ø¹ Ø§Ù„Ø¸Ù‡ÙˆØ± Ø®Ù„Ø§Ù„ 10 Ø¬ÙˆÙ„Ø§Øª")
    st.caption("Ø§Ù„Ù†Ø³Ø¨Ø© Ø£Ø³ÙÙ„ ÙƒÙ„ Ø®Ø§Ù†Ø© Ù‡ÙŠ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø¸Ù‡ÙˆØ± Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ø®Ù„Ø§Ù„ Ø§Ù„Ø¬ÙˆÙ„Ø§Øª Ø§Ù„Ø¹Ø´Ø± Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©.")

    def prob10(seg): return pct(p_at_least_once(p_next.get(seg, 0.0), 10))

    c1, c2 = st.columns(2)
    with c1:
        display_tile("1", f"â‰¥1 in 10: {prob10('1')}", letter_color("1"),
                     height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    with c2:
        display_tile("BAR", f"â‰¥1 in 10: {prob10('BAR')}", letter_color("BAR"),
                     height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(4)
    for i, L in enumerate(["P","L","A","Y"]):
        with cols[i]:
            display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L),
                         height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(5)
    for i, L in enumerate(["F","U","N","K","Y"]):
        with cols[i]:
            display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L if L!="Y" else "Y2"),
                         height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(4)
    for i, L in enumerate(["T","I","M","E"]):
        with cols[i]:
            display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L),
                         height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(3)
    for i, B in enumerate(["DISCO","STAYINALIVE","DISCO_VIP"]):
        label = "VIP DISCO" if B=="DISCO_VIP" else ("STAYIN'ALIVE" if B=="STAYINALIVE" else "DISCO")
        with cols[i]:
            display_tile(label, f"â‰¥1 in 10: {prob10(B)}", letter_color(B),
                         height=TILE_H_SMALL, txt_size=TILE_TXT_BONUS, sub_size=TILE_SUB_SMALL)

# ========== ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ==========
with tab_table:
    section_header("ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙƒÙ‡Ù‘Ù†Ø§Øª (10/15/25 Ùˆ Exp in 15)")
    if not df.empty:
        rows = []
        for s in ORDER:
            p = p_next.get(s, 0.0)
            rows.append({
                "Segment": "VIP DISCO" if s=="DISCO_VIP" else ("STAYIN'ALIVE" if s=="STAYINALIVE" else s),
                "â‰¥1 in 10": p_at_least_once(p, 10),
                "â‰¥1 in 15": p_at_least_once(p, 15),
                "â‰¥1 in 25": p_at_least_once(p, 25),
                "Exp in 15": exp_count(p, 15),
                "_color": letter_color("Y2" if s=="Y" else s),
            })
        tdf = pd.DataFrame(rows)

        def _fmt(v, col):
            return f"{v*100:.1f}%" if col in {"â‰¥1 in 10","â‰¥1 in 15","â‰¥1 in 25"} else (f"{v:.2f}" if col=="Exp in 15" else v)

        styled = (
            tdf.drop(columns=["_color"])
               .style.format({c: (lambda v, c=c: _fmt(v, c)) for c in ["â‰¥1 in 10","â‰¥1 in 15","â‰¥1 in 25","Exp in 15"]})
               .apply(lambda s: [f"background-color: {tdf.loc[i,'_color']}; color: white; font-weight:700"
                                 if s.name=="Segment" else "" for i in range(len(s))], axis=0)
        )
        st.dataframe(styled, use_container_width=True)
    else:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„.")

# ========== ØªØ¨ÙˆÙŠØ¨ Ø¹ÙŠÙ† Ø§Ù„ØµÙ‚Ø± ==========
with tab_falcon:
    section_header("Ø¹ÙŠÙ† Ø§Ù„ØµÙ‚Ø± â€” ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØªØ­Ø°ÙŠØ±Ø§Øª")

    if not df.empty:
        # Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 Ø®Ù„Ø§Ù„ 10/15/25
        any10 = 1.0
        any15 = 1.0
        any25 = 1.0
        for b in BONUS_SEGMENTS:
            pb = p_next.get(b, 0.0)
            any10 *= (1.0 - pb)**10
            any15 *= (1.0 - pb)**15
            any25 *= (1.0 - pb)**25
        any10 = 1.0 - any10
        any15 = 1.0 - any15
        any25 = 1.0 - any25

        c0, c1, c2 = st.columns(3)
        with c0:
            st.markdown(
                f"<div style='background:#5E35B1;padding:14px;border-radius:14px;font-weight:700;color:white'>"
                f"ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 10: <span style='float:right'>{pct(any10)}</span></div>",
                unsafe_allow_html=True
            )
        with c1:
            st.markdown(
                f"<div style='background:#00897B;padding:14px;border-radius:14px;font-weight:700;color:white'>"
                f"ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 15: <span style='float:right'>{pct(any15)}</span></div>",
                unsafe_allow_html=True
            )
        with c2:
            st.markdown(
                f"<div style='background:#6A1B9A;padding:14px;border-radius:14px;font-weight:700;color:white'>"
                f"ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 25: <span style='float:right'>{pct(any25)}</span></div>",
                unsafe_allow_html=True
            )

        st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)

        # ØªÙ‚Ø¯ÙŠØ±Ø§Øª ØªÙ‚Ø±ÙŠØ¨ÙŠØ©
        bonus10 = {b: p_at_least_once(p_next.get(b,0.0), 10) for b in BONUS_SEGMENTS}
        p50 = sum(bonus10.values()) * 0.25
        p100 = sum(bonus10.values()) * 0.10
        pLegend = sum(bonus10.values()) * 0.04

        d1, d2, d3 = st.columns(3)
        with d1:
            st.markdown(
                f"<div style='background:#F8E16C;padding:14px;border-radius:14px;font-weight:700'>"
                f"ğŸ Ø¨ÙˆÙ†Øµ â‰¥ Ã—50 ÙÙŠ 10: <span style='float:right'>{pct(p50)}</span></div>",
                unsafe_allow_html=True
            )
        with d2:
            st.markdown(
                f"<div style='background:#61C16D;padding:14px;border-radius:14px;font-weight:700;color:white'>"
                f"ğŸ’ Ø¨ÙˆÙ†Øµ â‰¥ Ã—100 ÙÙŠ 10: <span style='float:right'>{pct(p100)}</span></div>",
                unsafe_allow_html=True
            )
        with d3:
            st.markdown(
                f"<div style='background:#7C4DFF;padding:14px;border-radius:14px;font-weight:700;color:white'>"
                f"ğŸš€ Ø¨ÙˆÙ†Øµ Ø£Ø³Ø·ÙˆØ±ÙŠ (+100) ÙÙŠ 10: <span style='float:right'>{pct(pLegend)}</span></div>",
                unsafe_allow_html=True
            )

        st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)

        # ØªØºÙŠÙ‘ÙØ± Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù…Ø¨Ø³Ø·
        Wmini = min(30, len(df))
        if Wmini >= 10:
            tail = df.tail(Wmini)
            counts = tail["segment"].value_counts(normalize=True)
            meanp = counts.mean()
            varp = ((counts - meanp)**2).mean()
            if varp > 0.005:
                change_label = "High change"; badge = "<span style='color:#D32F2F;font-weight:700'>HIGH</span>"
            elif varp > 0.002:
                change_label = "Medium change"; badge = "<span style='color:#FB8C00;font-weight:700'>MEDIUM</span>"
            else:
                change_label = "Low change"; badge = "<span style='color:#2E7D32;font-weight:700'>LOW</span>"
        else:
            change_label = "Not enough data"; badge = "<span style='color:#999'>N/A</span>"

        st.markdown(
            f"<div style='background:#1E1E1E;color:#fff;padding:14px;border-radius:12px'>"
            f"ğŸ” Ø§Ù„ØªÙ‚Ù„Ø¨ Ø§Ù„Ø¹Ø§Ù…: {change_label} â€” {badge}</div>",
            unsafe_allow_html=True
        )

        st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)

        # Ø³ÙŠØ·Ø±Ø© Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø±Ù‚Ù… 1 Ø®Ù„Ø§Ù„ 15
        p1_next = p_next.get("1", 0.0)
        p1_in15 = p_at_least_once(p1_next, 15)
        color15 = "#D32F2F" if p1_in15 > 0.85 else "#37474F"
        st.markdown(
            f"<div style='background:{color15};color:#fff;padding:14px;border-radius:12px'>"
            f"âš ï¸ ØªØ­Ø°ÙŠØ±: Ø³ÙŠØ·Ø±Ø© Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø±Ù‚Ù… 1 Ø®Ù„Ø§Ù„ 15 Ø³Ø¨ÙÙ† â€” P(â‰¥1 Ø®Ù„Ø§Ù„ 15) = {pct(p1_in15)}</div>",
            unsafe_allow_html=True
        )

        # ØªÙƒØ±Ø§Ø± 1 Ø«Ù„Ø§Ø« Ù…Ø±Ø§Øª+ Ø®Ù„Ø§Ù„ 10
        def binom_tail_ge_k(n, p, k):
            p = max(0.0, min(1.0, float(p)))
            total = 0.0
            for r in range(0, k):
                total += math.comb(n, r) * (p**r) * ((1-p)**(n-r))
            return 1.0 - total

        p1_ge3_in10 = binom_tail_ge_k(10, p1_next, 3)
        st.markdown(
            f"<div style='background:#B71C1C;color:#fff;padding:14px;border-radius:12px'>"
            f"ğŸ›‘ ØªÙ†Ø¨ÙŠÙ‡ Ø­Ø§Ø¯: Ø§Ø­ØªÙ…Ø§Ù„ Ø£Ù† ÙŠØªÙƒØ±Ø± Ø§Ù„Ø±Ù‚Ù… <b>1</b> Ø«Ù„Ø§Ø« Ù…Ø±Ø§Øª Ø£Ùˆ Ø£ÙƒØ«Ø± Ø®Ù„Ø§Ù„ 10 Ø³Ø¨ÙÙ† = "
            f"<b>{pct(p1_ge3_in10)}</b> â€” ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ù…Ø¤Ù‚Øª.</div>",
            unsafe_allow_html=True
        )
    else:
        st.info("Ø£Ø¶Ù Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª.")

# ========== Ø£Ø³ÙÙ„ Ø§Ù„ØµÙØ­Ø© ==========
with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¢Ø®Ø± Ù†Ø§ÙØ°Ø©)"):
    if not df.empty:
        st.dataframe(df.tail(50), use_container_width=True)
    else:
        st.write("Ù„Ø§ Ø¨ÙŠØ§Ù†Ø§Øª.")

with st.expander("ØªÙ†Ø²ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬"):
    if os.path.exists(REPO_COMBINED_PATH):
        with open(REPO_COMBINED_PATH, "rb") as f:
            st.download_button(
                label="Download combined_spins.csv",
                data=f.read(),
                file_name="combined_spins.csv",
                mime="text/csv"
            )
    else:
        st.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ data/combined_spins.csv ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø¹Ø¯.")
