# app.py â€” Funky Brain LIVE (V3.1)
import os, math, pickle
import pandas as pd
import numpy as np
import streamlit as st
from datetime import datetime

st.set_page_config(page_title="Funky Brain LIVE", layout="wide")
st.title("ğŸ§  Funky Brain â€” LIVE")

DATA_DIR = "data"
REPO_COMBINED_PATH = os.path.join(DATA_DIR, "combined_spins.csv")

COLORS = {
    "ONE": "#F4D36B", "BAR": "#5AA64F",
    "ORANGE": "#E7903C", "PINK": "#C85C8E", "PURPLE": "#9A5BC2",
    "STAYINALIVE": "#4FC3D9", "DISCO": "#314E96", "DISCO_VIP": "#B03232",
}
LETTER_GROUP = {
    "P":"ORANGE","L":"ORANGE","A":"ORANGE","Y":"ORANGE",
    "F":"PINK","U":"PINK","N":"PINK","K":"PINK",
    "T":"PURPLE","I":"PURPLE","M":"PURPLE","E":"PURPLE",
}
BONUS_SEGMENTS = {"DISCO","STAYINALIVE","DISCO_VIP","BAR"}
ALL_SEGMENTS = {"1","BAR","P","L","A","Y","F","U","N","K","T","I","M","E","DISCO","STAYINALIVE","DISCO_VIP"}
ORDER = ["1","BAR","P","L","A","Y","F","U","N","K","T","I","M","E","DISCO","STAYINALIVE","DISCO_VIP"]

TILE_H=96; TILE_TXT=38; TILE_SUB=13
TILE_H_SMALL=84; TILE_TXT_SMALL=32; TILE_SUB_SMALL=12
TILE_TXT_BONUS=20

def pct(x): 
    try: return f"{float(x)*100:.1f}%"
    except: return "0.0%"

def p_at_least_once(p,n): return 1-(1-float(p))**int(n)
def exp_count(p,n): return float(n)*float(p)

def letter_color(s):
    if s in ("1","ONE"): return COLORS["ONE"]
    if s=="BAR": return COLORS["BAR"]
    if s in {"P","L","A","Y"}: return COLORS["ORANGE"]
    if s in {"F","U","N","K"}: return COLORS["PINK"]
    if s in {"T","I","M","E"}: return COLORS["PURPLE"]
    if s=="STAYINALIVE": return COLORS["STAYINALIVE"]
    if s=="DISCO": return COLORS["DISCO"]
    if s=="DISCO_VIP": return COLORS["DISCO_VIP"]
    return "#444"

def display_tile(label, subtext, bg, height=TILE_H, radius=16, txt_size=TILE_TXT, sub_size=TILE_SUB):
    st.markdown(
        f"""
        <div style="background:{bg};color:white;border-radius:{radius}px;height:{height}px;
                    display:flex;flex-direction:column;align-items:center;justify-content:center;font-weight:700;">
            <div style="font-size:{txt_size}px;line-height:1">{label}</div>
            <div style="font-size:{sub_size}px;opacity:.95;margin-top:2px">{subtext}</div>
        </div>""", unsafe_allow_html=True)

def section_header(t):
    st.markdown(f"<div style='font-size:20px;font-weight:700;margin:6px 0 10px'>{t}</div>", unsafe_allow_html=True)

# ---------- Ø§Ù„ØªÙ†Ø¸ÙŠÙ ----------
def clean_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    cols_lower = {c.lower(): c for c in df.columns}
    # ts
    guess_ts=None
    for k in ["ts","time","timestamp","date","datetime"]:
        if k in cols_lower: guess_ts=cols_lower[k]; break
    if guess_ts is None: 
        raise ValueError("Column missing: ts")
    # segment
    guess_seg=None
    for k in ["segment","result","tile","symbol","letter","outcome"]:
        if k in cols_lower: guess_seg=cols_lower[k]; break
    if guess_seg is None:
        for c in df.columns:
            if df[c].dtype==object:
                m = df[c].astype(str).str.extract(r"/([A-Za-z0-9_]+)\.png", expand=False)
                if m.notna().any():
                    df["segment"]=m.str.upper().str.replace("DISCOVIP","DISCO_VIP").str.replace("VIPDISCO","DISCO_VIP")
                    guess_seg="segment"; break
        if guess_seg is None: raise ValueError("Column missing: segment")
    # multiplier
    guess_mul=None
    for k in ["multiplier","multi","x","payout","winmult","factor"]:
        if k in cols_lower: guess_mul=cols_lower[k]; break
    if guess_mul is None:
        for c in df.columns:
            if df[c].dtype==object:
                m=df[c].astype(str).str.extract(r"(\d+)\s*[xX]", expand=False)
                if m.notna().any():
                    df["multiplier"]=m.fillna("1"); guess_mul="multiplier"; break
        if guess_mul is None: raise ValueError("Column missing: multiplier")

    df["ts"]=pd.to_datetime(df[guess_ts], errors="coerce")
    seg=df[guess_seg].astype(str).str.strip().str.upper()
    seg=seg.replace({"VIP DISCO":"DISCO_VIP","DISCO VIP":"DISCO_VIP","DISCOVIP":"DISCO_VIP",
                     "STAYIN'ALIVE":"STAYINALIVE","STAYIN_ALIVE":"STAYINALIVE","STAYIN-ALIVE":"STAYINALIVE"})
    seg=seg.str.replace(r"[^A-Z0-9_]","",regex=True)
    mul=(df[guess_mul].astype(str).str.extract(r"(\d+)\s*[xX]?", expand=False).fillna("1").astype(int).astype(str)+"X")
    out=pd.DataFrame({"ts":df["ts"],"segment":seg,"multiplier":mul}).dropna(subset=["ts"]).reset_index(drop=True)
    is_unknown=~out["segment"].isin(list(ALL_SEGMENTS))
    out.loc[is_unknown & out["multiplier"].eq("1X"),"segment"]="1"
    out.loc[~out["segment"].isin(list(ALL_SEGMENTS)),"segment"]="UNKNOWN"
    out=out.sort_values("ts")
    return out[["ts","segment","multiplier"]]

# ---------- Ø¯Ù…Ø¬ Ù…Ù„ÙØ§Øª data/spins_cleaned*.{csv,xlsx} ----------
def combine_inside_streamlit():
    os.makedirs(DATA_DIR, exist_ok=True)
    paths=[]
    for name in os.listdir(DATA_DIR):
        l=name.lower()
        if l.startswith("spins_cleaned") and (l.endswith(".csv") or l.endswith(".xlsx") or l.endswith(".xls")):
            paths.append(os.path.join(DATA_DIR,name))
    if not paths: return 0,"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù„ÙØ§Øª ØªØ¨Ø¯Ø£ Ø¨Ù€ spins_cleaned Ø¯Ø§Ø®Ù„ data/."
    frames=[]
    for p in sorted(paths):
        try:
            df = pd.read_csv(p) if p.lower().endswith(".csv") else pd.read_excel(p)
            frames.append(clean_df(df))
        except Exception as e:
            st.warning(f"ØªØ¬Ø§ÙˆØ² {os.path.basename(p)}: {e}")
    if not frames: return 0,"Ù„Ù… ÙŠÙØ­Ù…Ù‘ÙÙ„ Ø£ÙŠ Ù…Ù„Ù ØµØ§Ù„Ø­."
    big=pd.concat(frames, ignore_index=True)
    big=big.drop_duplicates(subset=["ts","segment","multiplier"]).sort_values("ts").reset_index(drop=True)
    big.to_csv(REPO_COMBINED_PATH, index=False, encoding="utf-8")
    return len(big), f"ØªÙ… Ø§Ù„Ø¯Ù…Ø¬ ÙÙŠ {REPO_COMBINED_PATH} â€” Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙÙˆÙ: {len(big):,}"

# ---------- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ----------
@st.cache_data(show_spinner=False)
def load_data(file, sheet_url, window, use_repo_file=False, repo_path=REPO_COMBINED_PATH):
    df=None
    if use_repo_file and os.path.exists(repo_path):
        try: df=pd.read_csv(repo_path)
        except Exception as e: st.warning(f"ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© {repo_path}: {e}")
    if df is None and file is not None:
        try:
            df=pd.read_csv(file) if file.name.lower().endswith(".csv") else pd.read_excel(file)
        except Exception as e:
            st.error(f"ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
            return pd.DataFrame(columns=["ts","segment","multiplier"])
    if df is None and sheet_url:
        url=sheet_url.strip()
        if "docs.google.com/spreadsheets" in url and "export?format=csv" not in url:
            try: gid=url.split("gid=")[-1]
            except: gid="0"
            doc_id=url.split("/d/")[1].split("/")[0]
            url=f"https://docs.google.com/spreadsheets/d/{doc_id}/export?format=csv&gid={gid}"
        try: df=pd.read_csv(url)
        except Exception as e:
            st.error(f"ØªØ¹Ø°Ù‘Ø± ØªØ­Ù…ÙŠÙ„ Google Sheets: {e}")
            return pd.DataFrame(columns=["ts","segment","multiplier"])
    if df is None:
        return pd.DataFrame(columns=["ts","segment","multiplier"])
    try: df=clean_df(df)
    except Exception as e:
        st.error(f"ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ØºÙŠØ± ØµØ§Ù„Ø­: {e}")
        return pd.DataFrame(columns=["ts","segment","multiplier"])
    if len(df)>window: df=df.tail(window).copy()
    return df.reset_index(drop=True)

# ---------- Ù†Ù…ÙˆØ°Ø¬ Recency/Softmax ----------
def recency_softmax_probs(df, horizon=10, temperature=1.6, decay_half_life=60, bonus_boost=1.15):
    dfx=df[~df["segment"].eq("UNKNOWN")].copy()
    if dfx.empty: dfx=df.copy()
    segs=list(ALL_SEGMENTS); n=len(dfx)
    if n==0:
        vec=np.ones(len(segs))
    else:
        ages=np.arange(n,0,-1)
        half=max(int(decay_half_life),1)
        w=np.power(0.5,(ages-1)/half); w=w/w.sum()
        counts={s:0.0 for s in segs}
        for seg,wt in zip(dfx["segment"], w):
            if seg in counts: counts[seg]+=wt
        vec=np.array([counts[s] for s in segs], dtype=float)
    for i,s in enumerate(segs):
        if s in BONUS_SEGMENTS: vec[i]*=float(bonus_boost)
    if vec.sum()<=0: vec[:]=1.0
    x=vec/(vec.std()+1e-9); x=x/max(float(temperature),1e-6)
    z=np.exp(x-x.max()); p_next=z/z.sum()
    probs=dict(zip(segs,p_next))
    p_in10={s:p_at_least_once(probs[s], horizon) for s in segs}
    return probs,p_in10

def get_probs(df,horizon=10,temperature=1.6,decay_half_life=60,bonus_boost=1.15):
    return recency_softmax_probs(df,horizon,temperature,decay_half_life,bonus_boost)

# ---------------- sidebar ----------------
with st.sidebar:
    st.subheader("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    window=st.slider("Window size (spins)",50,5000,120,step=10)
    horizon=st.slider("ØªÙˆÙ‚Ø¹ Ø¹Ù„Ù‰ ÙƒÙ… Ø¬ÙˆÙ„Ø©ØŸ",5,20,10,1)
    st.write("---")
    st.subheader("ğŸ›ï¸ Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤ (Recency/Softmax)")
    temperature=st.slider("Temperature (ØªØ±ÙƒÙŠØ² Ø§Ù„Ø³ÙˆÙØª-Ù…Ø§ÙƒØ³)",1.0,2.5,1.6,0.1)
    decay_half_life=st.slider("Half-life (ØªØ±Ø¬ÙŠØ­ Ø§Ù„Ø­Ø¯Ø§Ø«Ø©)",20,120,60,5)
    bonus_boost=st.slider("ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø¨ÙˆÙ†Øµ",1.00,1.40,1.15,0.05)
    st.write("---")

    st.subheader("ğŸ§© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    if st.button("ğŸ” Ø¯Ù…Ø¬ Ù…Ù„ÙØ§Øª data/spins_cleaned*.csv(xlsx) â†’ combined_spins.csv"):
        rows,msg=combine_inside_streamlit()
        if rows>0:
            st.success(msg); load_data.clear(); st.experimental_rerun()
        else: st.warning(msg)

    if os.path.exists(REPO_COMBINED_PATH):
        with open(REPO_COMBINED_PATH,"rb") as f:
            st.download_button("â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ combined_spins.csv", f.read(), file_name="combined_spins.csv", mime="text/csv")

    st.write("---")
    st.subheader("ğŸ“¥ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    use_repo_combined=st.toggle("Ø§Ø³ØªØ®Ø¯Ù… Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ data/combined_spins.csv", value=True)
    sheet_url=st.text_input("Ø±Ø§Ø¨Ø· Google Sheets (Ù…ÙØ¶Ù‘Ù„ CSV export)", value="")
    upload=st.file_uploader("â€¦Ø£Ùˆ Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV/Excel", type=["csv","xlsx","xls"])

    # ğŸ§¹ Ø²Ø± Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹
    if upload is not None:
        if st.button("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ + Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ combined_spins.csv", use_container_width=True):
            try:
                raw = pd.read_csv(upload) if upload.name.lower().endswith(".csv") else pd.read_excel(upload)
                cleaned = clean_df(raw)
                st.success(f"ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù â€” ØµÙÙˆÙ ØµØ§Ù„Ø­Ø©: {len(cleaned)}")
                st.dataframe(cleaned.tail(15), use_container_width=True)
                os.makedirs(DATA_DIR, exist_ok=True)
                if os.path.exists(REPO_COMBINED_PATH):
                    base = pd.read_csv(REPO_COMBINED_PATH)
                    base = pd.concat([base, cleaned], ignore_index=True)
                else:
                    base = cleaned.copy()
                base = (base.drop_duplicates(subset=["ts","segment","multiplier"])
                             .sort_values("ts").reset_index(drop=True))
                base.to_csv(REPO_COMBINED_PATH, index=False, encoding="utf-8")
                st.success(f"Ø£ÙØ¶ÙŠÙ Ø¥Ù„Ù‰ {REPO_COMBINED_PATH}. Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¢Ù†: {len(base):,}")
                load_data.clear()
            except Exception as e:
                st.error(f"ÙØ´Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ/Ø§Ù„Ø¥Ø¶Ø§ÙØ©: {e}")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
df = load_data(upload, sheet_url, window, use_repo_file=use_repo_combined, repo_path=REPO_COMBINED_PATH)
if df.empty:
    st.info("Ø£Ø¶Ù Ù…ØµØ¯Ø± Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­ ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: ts, segment, multiplier")
    st.stop()

# -------- Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ¹Ù„Ù‘Ù… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) --------
with st.sidebar:
    st.markdown("---")
    st.subheader("ğŸ¤– Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ¹Ù„Ù‘Ù… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    use_learned = st.toggle("Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ØªØ¹Ù„Ù‘ÙÙ… Ø¥Ù† ÙˆÙØ¬Ø¯", value=False)
    model_path_to_use = st.text_input("Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", value="models/pattern_model.pkl", key="use_model_path")
    learned_pnext=None; model_meta=None
    if use_learned:
        try:
            with open(model_path_to_use,"rb") as f:
                model_obj=pickle.load(f)
            learned_pnext=model_obj.get("p_next",None)
            model_meta=model_obj.get("meta",{})
            if not isinstance(learned_pnext,dict) or len(learned_pnext)==0:
                st.error("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ­Ù…Ù‘Ù„ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ p_next ØµØ§Ù„Ø­."); learned_pnext=None
        except Exception as e:
            st.error(f"ØªØ¹Ø°Ù‘Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
        if model_meta:
            with st.expander("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (meta)"):
                st.json(model_meta)

if use_learned and learned_pnext:
    p_next={s:float(learned_pnext.get(s,0.0)) for s in ALL_SEGMENTS}
else:
    p_next,_=recency_softmax_probs(df, horizon=10, temperature=temperature, decay_half_life=decay_half_life, bonus_boost=bonus_boost)

# -------- Tabs --------
tab_tiles, tab_board, tab_table, tab_falcon = st.tabs(["ğŸ›ï¸ Tiles","ğŸ¯ Board + 10 Spins","ğŸ“Š Table","ğŸ¦… Falcon Eye"])

with tab_tiles:
    section_header("Ù„ÙˆØ­Ø© Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª (Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØµØµØ©)")
    c1,c2,_,_=st.columns([1.2,1.2,0.1,0.1])
    with c1: display_tile("1", f"P(next) {pct(p_next.get('1',0))}", letter_color("1"))
    with c2: display_tile("BAR", f"P(next) {pct(p_next.get('BAR',0))}", letter_color("BAR"), txt_size=34)
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(4)
    for i,L in enumerate(["P","L","A","Y"]): 
        with cols[i]: display_tile(L, f"P(next) {pct(p_next.get(L,0))}", letter_color(L))
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(4)
    for i,L in enumerate(["F","U","N","K"]):
        with cols[i]: display_tile(L, f"P(next) {pct(p_next.get(L,0))}", letter_color(L))
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(4)
    for i,L in enumerate(["T","I","M","E"]):
        with cols[i]: display_tile(L, f"P(next) {pct(p_next.get(L,0))}", letter_color(L))
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(3)
    for i,B in enumerate(["DISCO","STAYINALIVE","DISCO_VIP"]):
        label="VIP DISCO" if B=="DISCO_VIP" else ("STAYIN'ALIVE" if B=="STAYINALIVE" else "DISCO")
        with cols[i]:
            display_tile(label, f"P(next) {pct(p_next.get(B,0))}", letter_color(B), height=TILE_H, txt_size=TILE_TXT_BONUS)

with tab_board:
    section_header("Ù„ÙˆØ­Ø© Ø§Ù„Ø±Ù‡Ø§Ù† + ØªÙˆÙ‚Ø¹ Ø§Ù„Ø¸Ù‡ÙˆØ± Ø®Ù„Ø§Ù„ 10 Ø¬ÙˆÙ„Ø§Øª")
    def prob10(seg): return pct(p_at_least_once(p_next.get(seg,0.0),10))
    c1,c2=st.columns(2)
    with c1: display_tile("1", f"â‰¥1 in 10: {prob10('1')}", letter_color("1"), height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    with c2: display_tile("BAR", f"â‰¥1 in 10: {prob10('BAR')}", letter_color("BAR"), height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(4)
    for i,L in enumerate(["P","L","A","Y"]):
        with cols[i]: display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L), height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(4)
    for i,L in enumerate(["F","U","N","K"]):
        with cols[i]: display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L), height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(4)
    for i,L in enumerate(["T","I","M","E"]):
        with cols[i]: display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L), height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(3)
    for i,B in enumerate(["DISCO","STAYINALIVE","DISCO_VIP"]):
        label="VIP DISCO" if B=="DISCO_VIP" else ("STAYIN'ALIVE" if B=="STAYINALIVE" else "DISCO")
        with cols[i]: display_tile(label, f"â‰¥1 in 10: {prob10(B)}", letter_color(B), height=TILE_H_SMALL, txt_size=TILE_TXT_BONUS, sub_size=TILE_SUB_SMALL)

with tab_table:
    section_header("ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙƒÙ‡Ù‘Ù†Ø§Øª (10/15/25 Ùˆ Exp in 15)")
    rows=[]
    for s in ORDER:
        p=p_next.get(s,0.0)
        rows.append({
            "Segment": "VIP DISCO" if s=="DISCO_VIP" else ("STAYIN'ALIVE" if s=="STAYINALIVE" else s),
            "â‰¥1 in 10": p_at_least_once(p,10),
            "â‰¥1 in 15": p_at_least_once(p,15),
            "â‰¥1 in 25": p_at_least_once(p,25),
            "Exp in 15": exp_count(p,15),
            "_color": letter_color("1" if s=="1" else s),
        })
    tdf=pd.DataFrame(rows)

    def _fmt(v,col):
        return f"{v*100:.1f}%" if col in {"â‰¥1 in 10","â‰¥1 in 15","â‰¥1 in 25"} else (f"{v:.2f}" if col=="Exp in 15" else v)

    base = tdf.drop(columns=["_color"]).style.format({c:(lambda v,c=c:_fmt(v,c)) for c in ["â‰¥1 in 10","â‰¥1 in 15","â‰¥1 in 25","Exp in 15"]})
    # ØªÙ„ÙˆÙŠÙ† Ø¹Ù…ÙˆØ¯ Segment ØµÙØ§Ù‹ Ø¨ØµÙ:
    def color_segment_col(col):
        if col.name!="Segment": return [""]*len(col)
        return [f"background-color: {tdf.loc[i,'_color']}; color: white; font-weight:700" for i in range(len(col))]
    styled = base.apply(color_segment_col, axis=0)
    st.dataframe(styled, use_container_width=True)

with tab_falcon:
    section_header("Ø¹ÙŠÙ† Ø§Ù„ØµÙ‚Ø± â€” ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØªØ­Ø°ÙŠØ±Ø§Øª")
    any10=1.0; any15=1.0; any25=1.0
    for b in BONUS_SEGMENTS:
        pb=p_next.get(b,0.0)
        any10*=(1-pb)**10; any15*=(1-pb)**15; any25*=(1-pb)**25
    any10=1-any10; any15=1-any15; any25=1-any25
    c0,c1,c2=st.columns(3)
    with c0: st.markdown(f"<div style='background:#1565C0;padding:14px;border-radius:14px;font-weight:700;color:white'>ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 10: <span style='float:right'>{pct(any10)}</span></div>", unsafe_allow_html=True)
    with c1: st.markdown(f"<div style='background:#00897B;padding:14px;border-radius:14px;font-weight:700;color:white'>ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 15: <span style='float:right'>{pct(any15)}</span></div>", unsafe_allow_html=True)
    with c2: st.markdown(f"<div style='background:#6A1B9A;padding:14px;border-radius:14px;font-weight:700;color:white'>ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 25: <span style='float:right'>{pct(any25)}</span></div>", unsafe_allow_html=True)

    def binom_tail_ge_k(n,p,k):
        p=max(0,min(1,float(p))); tot=0.0
        for r in range(0,k):
            tot+=math.comb(n,r)*(p**r)*((1-p)**(n-r))
        return 1.0-tot
    p1_next=p_next.get("1",0.0)
    p1_in15=p_at_least_once(p1_next,15)
    color15="#D32F2F" if p1_in15>0.85 else "#37474F"
    st.markdown(f"<div style='background:{color15};color:#fff;padding:14px;border-radius:12px'>âš ï¸ ØªØ­Ø°ÙŠØ±: Ø³ÙŠØ·Ø±Ø© Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø±Ù‚Ù… 1 Ø®Ù„Ø§Ù„ 15 Ø³Ø¨ÙÙ† â€” P(â‰¥1 Ø®Ù„Ø§Ù„ 15) = {pct(p1_in15)}</div>", unsafe_allow_html=True)
    p1_ge3_in10=binom_tail_ge_k(10,p1_next,3)
    st.markdown(f"<div style='background:#B71C1C;color:#fff;padding:14px;border-radius:12px'>ğŸ›‘ ØªÙ†Ø¨ÙŠÙ‡ Ø­Ø§Ø¯: Ø§Ø­ØªÙ…Ø§Ù„ Ø£Ù† ÙŠØªÙƒØ±Ø± Ø§Ù„Ø±Ù‚Ù… <b>1</b> Ø«Ù„Ø§Ø« Ù…Ø±Ø§Øª Ø£Ùˆ Ø£ÙƒØ«Ø± Ø®Ù„Ø§Ù„ 10 Ø³Ø¨ÙÙ† = <b>{pct(p1_ge3_in10)}</b> â€” ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ù…Ø¤Ù‚Øª.</div>", unsafe_allow_html=True)

with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¢Ø®Ø± Ù†Ø§ÙØ°Ø©)"):
    st.dataframe(df.tail(50), use_container_width=True)

# -------- ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ --------
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ¤– ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
model_path_input=st.sidebar.text_input("Ù…Ø³Ø§Ø± Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", value="models/pattern_model.pkl", key="train_model_path")
with st.sidebar.expander("Ù…Ù„Ø®Øµ Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"):
    st.write(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ù…ÙŠØ§Øª ÙÙŠ Ø§Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: **{len(df)}**")
    st.write("Ø£Ø¹Ù…Ø¯Ø©:", list(df.columns))
    st.dataframe(df.tail(10), use_container_width=True)

def train_and_save_model(df, path, horizon, temperature, decay_half_life, bonus_boost):
    p_next_tr,_=recency_softmax_probs(df,horizon,temperature,decay_half_life,bonus_boost)
    model={"type":"recency_softmax","p_next":p_next_tr,"meta":{"horizon":horizon,"temperature":temperature,
           "half_life":decay_half_life,"bonus_boost":bonus_boost,"trained_on_rows":int(len(df)),
           "trained_at":datetime.utcnow().isoformat()+"Z"}}
    os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
    with open(path,"wb") as f: pickle.dump(model,f)
    return model

if st.sidebar.button("ğŸ’¾ Ø¯Ø±Ù‘ÙØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¢Ù†", use_container_width=True):
    if df.empty:
        st.sidebar.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨.")
    else:
        try:
            _=train_and_save_model(df, model_path_input, horizon, temperature, decay_half_life, bonus_boost)
            st.sidebar.success(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {model_path_input}")
            with open(model_path_input,"rb") as fh:
                st.sidebar.download_button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", fh.read(),
                    file_name=os.path.basename(model_path_input) or "pattern_model.pkl",
                    mime="application/octet-stream", use_container_width=True)
        except Exception as e:
            st.sidebar.error(f"ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")
st.sidebar.markdown("---")
st.sidebar.caption("Ø¨Ø¹Ø¯ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ø±ÙØ¹Ù‡ Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ models/ ÙÙŠ GitHub.")
