# app.py â€” Funky Brain LIVE (Stable + Data Cleaner + Model Switch)
# - ÙŠÙ‚Ø±Ø£ Ù…Ù† data/combined_spins.csv Ø£Ùˆ Ø±ÙØ¹ Ù…Ù„Ù/Google Sheets
# - ØªÙ†Ø¸ÙŠÙ Ø°ÙƒÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù… (ts/segment/multiplier) ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ segment Ù…Ù† Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØµÙˆØ±
# - Ø²Ø± ØªÙ†Ø¸ÙŠÙ+Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹ + Ø²Ø± Ø¯Ù…Ø¬ Ù…Ù„ÙØ§Øª data/spins_cleaned*.*
# - Ù†Ù…ÙˆØ°Ø¬ Recency+Softmax + Ø®ÙŠØ§Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ¹Ù„Ù‘Ù… pattern_model.pkl
# - ØªØ¨ÙˆÙŠØ¨Ø§Øª: Tiles / Board + 10 / Table / Falcon Eye
# - ØªØ­Ø°ÙŠØ±: Ø§Ø­ØªÙ…Ø§Ù„ ØªÙƒØ±Ø§Ø± "1" â‰¥ 3 Ù…Ø±Ø§Øª ÙÙŠ 10 Ø±Ù…ÙŠØ§Øª

import os, re, math, pickle
import pandas as pd
import numpy as np
import streamlit as st
from datetime import datetime

# ===== Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯ÙˆØ§Ù„Ù‘Ùƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¥Ù† ÙˆÙØ¬Ø¯Øª (Ù„Ù† Ù†ÙƒØ³Ø± Ø´ÙŠØ¦Ù‹Ø§) =====
_HAS_CORE = False
try:
    from funkybrain_core import normalize_df, compute_probs, board_model
    _HAS_CORE = True
except Exception:
    _HAS_CORE = False

# ------------------------ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø© ------------------------
st.set_page_config(page_title="Funky Brain LIVE", layout="wide")
st.title("ğŸ§  Funky Brain â€” LIVE")

DATA_DIR = "data"
REPO_COMBINED_PATH = os.path.join(DATA_DIR, "combined_spins.csv")

# Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª
COLORS = {
    "ONE": "#F4D36B", "BAR": "#5AA64F",
    "ORANGE": "#E7903C", "PINK": "#C85C8E", "PURPLE": "#9A5BC2",
    "STAYINALIVE": "#4FC3D9", "DISCO": "#314E96", "DISCO_VIP": "#B03232",
}
BONUS_SEGMENTS = {"DISCO","STAYINALIVE","DISCO_VIP","BAR"}
ALL_SEGMENTS = {
    "1","BAR","P","L","A","Y","F","U","N","K","Y","T","I","M","E",
    "DISCO","STAYINALIVE","DISCO_VIP"
}
ORDER = ["1","BAR","P","L","A","Y","F","U","N","K","Y","T","I","M","E","DISCO","STAYINALIVE","DISCO_VIP"]

# Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª
TILE_H=96; TILE_TXT=38; TILE_SUB=13
TILE_H_SMALL=84; TILE_TXT_SMALL=32; TILE_SUB_SMALL=12
TILE_TXT_BONUS=20

# ------------------------ ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© ------------------------
def pct(x: float) -> str:
    try: return f"{float(x)*100:.1f}%"
    except Exception: return "0.0%"

def p_at_least_once(p: float, n: int) -> float:
    return 1.0 - (1.0 - float(p))**int(n)

def exp_count(p: float, n: int) -> float:
    return float(n) * float(p)

def letter_color(letter: str) -> str:
    if letter in {"1","ONE"}: return COLORS["ONE"]
    if letter=="BAR": return COLORS["BAR"]
    if letter in {"P","L","A","Y"}: return COLORS["ORANGE"]
    if letter in {"F","U","N","K","Y","Y2"}: return COLORS["PINK"]
    if letter in {"T","I","M","E"}: return COLORS["PURPLE"]
    if letter=="STAYINALIVE": return COLORS["STAYINALIVE"]
    if letter=="DISCO": return COLORS["DISCO"]
    if letter=="DISCO_VIP": return COLORS["DISCO_VIP"]
    return "#444"

def display_tile(label, subtext, bg, height=TILE_H, radius=16, txt_size=TILE_TXT, sub_size=TILE_SUB):
    st.markdown(
        f"""
        <div style="background:{bg};color:white;border-radius:{radius}px;height:{height}px;
                    display:flex;flex-direction:column;align-items:center;justify-content:center;font-weight:700;">
            <div style="font-size:{txt_size}px;line-height:1">{label if label!='Y2' else 'Y'}</div>
            <div style="font-size:{sub_size}px;opacity:.95;margin-top:2px">{subtext}</div>
        </div>
        """, unsafe_allow_html=True
    )

def section_header(title):
    st.markdown(f"<div style='font-size:20px;font-weight:700;margin:6px 0 10px'>{title}</div>", unsafe_allow_html=True)

# ---------- ØªØ®Ù…ÙŠÙ† Ø§Ù„Ù‚Ø·Ø§Ø¹ Ù…Ù† Ø§Ø³Ù… Ù…Ù„Ù Ø§Ù„ØµÙˆØ±Ø© ----------
def _guess_segment_from_url(url: str) -> str | None:
    s = str(url).lower()
    patterns = [
        (r"(disco[_\-]?(vip|v|vip1)|discovip)", "DISCO_VIP"),
        (r"(stay[_\-]?(in)?alive|stayinalive|stayalive)", "STAYINALIVE"),
        (r"/bar(\.png|\.jpg|/|$)", "BAR"),
        (r"/disco(\.png|\.jpg|/|$)", "DISCO"),
        (r"/1(\.png|\.jpg|/|$)", "1"),
    ]
    for L in list("PLAYFUNKYTIME"):
        patterns.append((rf"/{L.lower()}(\.png|\.jpg|/|$)", L))
    for pat, lab in patterns:
        if re.search(pat, s):
            return lab
    return None

def _refine_unknown_with_url(df_raw: pd.DataFrame, seg_series: pd.Series, mult_series: pd.Series):
    url_col = None
    for c in ["image","img","src","url","href"]:
        if c in df_raw.columns:
            url_col = c; break
    if url_col is None:
        return seg_series, mult_series
    hints = df_raw[url_col].astype(str).apply(_guess_segment_from_url)
    mask = (seg_series.str.upper().eq("UNKNOWN")) & (mult_series.str.upper().eq("16X")) & (hints=="1")
    seg_series = seg_series.copy(); mult_series = mult_series.copy()
    seg_series.loc[mask] = "1"; mult_series.loc[mask] = "1X"
    return seg_series, mult_series

# ---------- Ù…Ù†Ø¸Ù‘Ù Ù…Ø±Ù† ----------
def clean_df(df: pd.DataFrame) -> pd.DataFrame:
    df_raw = df.copy()

    # ts
    ts_col = None
    for cand in ["ts", "timestamp", "datetime"]:
        if cand in df_raw.columns:
            ts_col = cand; break
    if ts_col is None and ("date" in df_raw.columns and "time" in df_raw.columns):
        df_raw["ts"] = (df_raw["date"].astype(str).str.strip() + " " + df_raw["time"].astype(str).str.strip())
        ts_col = "ts"
    if ts_col is None:
        for c in df_raw.columns:
            sample = str(df_raw[c].astype(str).dropna().head(6).tolist())
            if re.search(r"\d{4}[-/]\d{1,2}[-/]\d{1,2}", sample) or re.search(r"\d{1,2}:\d{2}", sample):
                ts_col = c; break
    if ts_col is None:
        raise ValueError("Column missing: ts")
    ts = pd.to_datetime(df_raw[ts_col], errors="coerce")

    # multiplier
    mult_col = "multiplier" if "multiplier" in df_raw.columns else None
    if mult_col is None:
        for c in df_raw.columns:
            vals = df_raw[c].astype(str)
            if (vals.str.contains(r"\d+\s*[xX]$", regex=True).mean() > 0.3) or \
               (vals.str.contains(r"^\s*\d+\s*(?:x|X)?\s*$", regex=True).mean() > 0.5):
                mult_col = c; break
    if mult_col is None:
        num_like = [c for c in df_raw.columns if pd.to_numeric(df_raw[c], errors="coerce").notna().mean() > 0.5]
        if num_like: mult_col = num_like[0]
        else: raise ValueError("Column missing: multiplier")
    mult = (
        df_raw[mult_col].astype(str)
        .str.extract(r"(\d+)\s*[xX]?", expand=False)
        .fillna("1").astype(int).astype(str) + "X"
    )

    # segment
    seg_col = "segment" if "segment" in df_raw.columns else None
    if seg_col is None:
        for c in ["symbol","result","letter","tile","name"]:
            if c in df_raw.columns:
                seg_col = c; break
    if seg_col is None:
        url_col = None
        for c in ["image","img","src","url","href"]:
            if c in df_raw.columns:
                url_col = c; break
        if url_col is not None:
            seg = df_raw[url_col].astype(str).apply(_guess_segment_from_url).fillna("UNKNOWN")
        else:
            seg = pd.Series(["UNKNOWN"]*len(df_raw))
    else:
        seg = df_raw[seg_col].astype(str).str.strip().str.upper()

    seg = seg.str.upper().replace({"ONE":"1"})
    mult = mult.where(~seg.eq("1"), "1X")
    seg, mult = _refine_unknown_with_url(df_raw, seg, mult)

    out = pd.DataFrame({"ts": ts, "segment": seg, "multiplier": mult})
    out = out.dropna(subset=["ts"]).sort_values("ts").reset_index(drop=True)
    return out[["ts","segment","multiplier"]]

# ---------- Ø¯Ù…Ø¬ Ù…Ù„ÙØ§Øª Ø¯Ø§Ø®Ù„ data/ ----------
def combine_inside_streamlit() -> tuple[int, str]:
    os.makedirs(DATA_DIR, exist_ok=True)
    paths = []
    for name in os.listdir(DATA_DIR):
        low = name.lower()
        if low.startswith("spins_cleaned") and low.endswith((".csv",".xlsx",".xls")):
            paths.append(os.path.join(DATA_DIR, name))
    if not paths:
        return 0, "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª ØªØ¨Ø¯Ø£ Ø¨Ù€ spins_cleaned Ø¯Ø§Ø®Ù„ data/."
    frames = []
    for p in sorted(paths):
        try:
            df = pd.read_csv(p) if p.lower().endswith(".csv") else pd.read_excel(p)
            frames.append(clean_df(df))
        except Exception as e:
            st.warning(f"ØªØ¬Ø§ÙˆØ² {os.path.basename(p)}: {e}")
    if not frames: return 0, "Ù„Ù… Ø£Ø³ØªØ·Ø¹ Ù‚Ø±Ø§Ø¡Ø© Ø£ÙŠ Ù…Ù„Ù ØµØ§Ù„Ø­."
    big = pd.concat(frames, ignore_index=True)
    big = big.drop_duplicates(subset=["ts","segment","multiplier"]).sort_values("ts").reset_index(drop=True)
    big.to_csv(REPO_COMBINED_PATH, index=False, encoding="utf-8")
    return len(big), f"ØªÙ… Ø§Ù„Ø¯Ù…Ø¬ ÙÙŠ {REPO_COMBINED_PATH} â€” Ø§Ù„ØµÙÙˆÙ: {len(big):,}"

# ---------- ØªÙ†Ø¸ÙŠÙ Ù…Ù„Ù Ù…Ø±ÙÙˆØ¹ ÙˆØ¥Ù„Ø­Ø§Ù‚Ù‡ Ø¨Ù€ combined_spins.csv ----------
def clean_and_append_uploaded(upload_file) -> pd.DataFrame:
    if upload_file is None:
        raise ValueError("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ù…Ø±ÙÙˆØ¹.")
    raw = pd.read_csv(upload_file) if upload_file.name.lower().endswith(".csv") else pd.read_excel(upload_file)
    cleaned = clean_df(raw)

    os.makedirs(DATA_DIR, exist_ok=True)
    if os.path.exists(REPO_COMBINED_PATH):
        # âœ… Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ØªØ¹Ø§Ø±Ø¶: Ø·Ø¨Ù‘Ù‚ clean_df Ø¯ÙˆÙ…Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ (ts ÙƒÙ€ datetime)
        base_raw = pd.read_csv(REPO_COMBINED_PATH)
        base = clean_df(base_raw)
        out = (pd.concat([base, cleaned], ignore_index=True)
                 .drop_duplicates(subset=["ts","segment","multiplier"])
                 .sort_values("ts").reset_index(drop=True))
    else:
        out = cleaned.copy()

    out.to_csv(REPO_COMBINED_PATH, index=False, encoding="utf-8")
    return cleaned

# ---------- Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (repo / upload / sheets) ----------
@st.cache_data(show_spinner=False)
def load_data(file, sheet_url, window, use_repo_file=False, repo_path=REPO_COMBINED_PATH):
    df = None
    if use_repo_file and os.path.exists(repo_path):
        try: df = pd.read_csv(repo_path)
        except Exception as e: st.warning(f"ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© {repo_path}: {e}")

    if df is None and file is not None:
        try:
            df = pd.read_csv(file) if file.name.lower().endswith(".csv") else pd.read_excel(file)
        except Exception as e:
            st.error(f"ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
            return pd.DataFrame(columns=["ts","segment","multiplier"])

    if df is None and sheet_url:
        url = sheet_url.strip()
        if "docs.google.com/spreadsheets" in url and "export?format=csv" not in url:
            try: gid = url.split("gid=")[-1]
            except Exception: gid = "0"
            doc_id = url.split("/d/")[1].split("/")[0]
            url = f"https://docs.google.com/spreadsheets/d/{doc_id}/export?format=csv&gid={gid}"
        try: df = pd.read_csv(url)
        except Exception as e:
            st.error(f"ØªØ¹Ø°Ù‘Ø± ØªØ­Ù…ÙŠÙ„ Google Sheets: {e}")
            return pd.DataFrame(columns=["ts","segment","multiplier"])

    if df is None:
        return pd.DataFrame(columns=["ts","segment","multiplier"])

    try:
        df = clean_df(df)
    except Exception as e:
        st.error(f"ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ØºÙŠØ± ØµØ§Ù„Ø­: {e}")
        return pd.DataFrame(columns=["ts","segment","multiplier"])

    if len(df) > window: df = df.tail(window).copy()
    return df.reset_index(drop=True)

# -------- Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª: Recency + Softmax + Bonus boost --------
def recency_softmax_probs(df, horizon=10, temperature=1.6, decay_half_life=60, bonus_boost=1.15):
    try:
        dfx = df[~df["segment"].eq("UNKNOWN")].copy()
        if dfx.empty: dfx = df.copy()
        segs = list(ALL_SEGMENTS); n = len(dfx)
        if n == 0:
            vec = np.ones(len(segs), dtype=float)
        else:
            ages = np.arange(n, 0, -1)               # Ø§Ù„Ø£Ø­Ø¯Ø« Ø¹Ù…Ø±Ù‡ 1
            half = max(int(decay_half_life), 1)
            w = np.power(0.5, (ages-1)/half); w = w / w.sum()
            counts = {s:0.0 for s in segs}
            for seg, wt in zip(dfx["segment"], w):
                if seg in counts: counts[seg] += wt
            vec = np.array([counts[s] for s in segs], dtype=float)
        for i,s in enumerate(segs):
            if s in BONUS_SEGMENTS: vec[i] *= float(bonus_boost)
        if vec.sum() <= 0: vec[:] = 1.0
        x = vec / (vec.std()+1e-9); x = x / max(float(temperature),1e-6)
        z = np.exp(x-x.max()); p_next = z/z.sum()
        probs = dict(zip(segs,p_next))
        p_in10 = {s: p_at_least_once(probs[s], horizon) for s in segs}
        return probs, p_in10
    except Exception:
        counts = df["segment"].value_counts()
        segs = list(ALL_SEGMENTS)
        vec = np.array([counts.get(s,0) for s in segs], dtype=float)
        if vec.sum()==0: vec[:] = 1.0
        z = np.exp((vec-vec.mean())/(vec.std()+1e-6)); p = z/z.sum()
        probs = dict(zip(segs,p))
        p_in10 = {s: p_at_least_once(probs[s], horizon) for s in segs}
        return probs,p_in10

def get_probs_recency(df, **kw):
    return recency_softmax_probs(df, **kw)

# ------------------------ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (Sidebar) ------------------------
with st.sidebar:
    st.subheader("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    window = st.slider("Window size (spins)", 50, 300, 120, step=10)
    horizon = st.slider("ØªÙˆÙ‚Ø¹ Ø¹Ù„Ù‰ ÙƒÙ… Ø¬ÙˆÙ„Ø©ØŸ", 5, 20, 10, step=1)
    st.write("---")

    st.subheader("ğŸ›ï¸ Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤ (Recency/Softmax)")
    temperature = st.slider("Temperature", 1.0, 2.5, 1.6, 0.1)
    decay_half_life = st.slider("Half-life", 20, 120, 60, 5)
    bonus_boost = st.slider("Bonus Boost", 1.00, 1.40, 1.15, 0.05)

    st.write("---")
    st.subheader("ğŸ§© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    if st.button("ğŸ” Ø¯Ù…Ø¬ Ù…Ù„ÙØ§Øª data/spins_cleaned*.csv(xlsx) â†’ combined_spins.csv", use_container_width=True):
        rows, msg = combine_inside_streamlit()
        if rows>0:
            st.success(msg)
            load_data.clear(); st.experimental_rerun()
        else:
            st.warning(msg)

    if os.path.exists(REPO_COMBINED_PATH):
        with open(REPO_COMBINED_PATH, "rb") as f:
            st.download_button("â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ combined_spins.csv", f.read(), file_name="combined_spins.csv", mime="text/csv", use_container_width=True)

    st.write("---")
    st.subheader("ğŸ“¥ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    use_repo_combined = st.toggle("Ø§Ø³ØªØ®Ø¯Ù… Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ data/combined_spins.csv", value=True)
    sheet_url = st.text_input("Ø±Ø§Ø¨Ø· Google Sheets (CSV export)", value="")
    upload = st.file_uploader("â€¦Ø£Ùˆ Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV/Excel", type=["csv","xlsx","xls"])

    if upload is not None:
        if st.button("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ + Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ combined_spins.csv", use_container_width=True):
            try:
                preview = clean_and_append_uploaded(upload)
                st.success("ØªÙ…Ù‘ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù ÙˆØ¥Ù„Ø­Ø§Ù‚Ù‡ Ø¨Ù€ combined_spins.csv âœ…")
                with st.expander("Ù…Ø¹Ø§ÙŠÙ†Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ (Ø£ÙˆÙ„ 20 ØµÙ)"):
                    st.dataframe(preview.head(20), use_container_width=True)
                load_data.clear(); st.experimental_rerun()
            except Exception as e:
                st.error(f"ÙØ´Ù„ ØªÙ†Ø¸ÙŠÙ/Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø®Ø§Ù…: {e}")

    st.write("---")
    st.subheader("ğŸ¤– Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ¹Ù„Ù‘Ù… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    use_learned = st.toggle("Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ØªØ¹Ù„Ù‘Ù… Ø¥Ù† ÙˆØ¬Ø¯", value=False)
    model_path = st.text_input("Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", value="models/pattern_model.pkl")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¯Ø§ØªØ§
df = load_data(upload if not use_repo_combined else None, sheet_url, window,
               use_repo_file=use_repo_combined, repo_path=REPO_COMBINED_PATH)
if df.empty:
    st.info("Ø£Ø¶Ù Ù…ØµØ¯Ø± Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­ ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: ts, segment, multiplier")
    st.stop()

# -------- Ø§Ø®ØªÙŠØ§Ø± Ù…ØµØ¯Ø± Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª --------
source_label = "recency"; p_next={}; p_in10={}
if use_learned and os.path.exists(model_path):
    try:
        with open(model_path, "rb") as fh: model_obj = pickle.load(fh)
        if isinstance(model_obj, dict) and "p_next" in model_obj:
            p_next = model_obj["p_next"]
            p_in10 = {s: p_at_least_once(p_next.get(s,0.0), horizon) for s in ALL_SEGMENTS}
            source_label = "learned-model"
            with st.expander("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (meta)"):
                st.json(model_obj.get("meta", {}))
        else:
            st.warning("Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ p_next â€” Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… recency.")
    except Exception as e:
        st.warning(f"ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
if not p_next:
    p_next, p_in10 = get_probs_recency(df, horizon=horizon, temperature=temperature, decay_half_life=decay_half_life, bonus_boost=bonus_boost)
st.caption(f"Source of probabilities: {source_label}")

# ØªØ¨ÙˆÙŠØ¨Ø§Øª
tab_tiles, tab_board, tab_table, tab_falcon = st.tabs(["ğŸ›ï¸ Tiles", "ğŸ¯ Board + 10 Spins", "ğŸ“Š Table", "ğŸ¦… Falcon Eye"])

# ========== Tiles ==========
with tab_tiles:
    section_header("Ù„ÙˆØ­Ø© Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª (Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØµØµØ©)")
    c1,c2,_,_=st.columns([1.2,1.2,0.1,0.1])
    with c1: display_tile("1", f"P(next) {pct(p_next.get('1',0))}", letter_color("1"))
    with c2: display_tile("BAR", f"P(next) {pct(p_next.get('BAR',0))}", letter_color("BAR"), txt_size=34)
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(4)
    for i,L in enumerate(["P","L","A","Y"]):
        with cols[i]: display_tile(L, f"P(next) {pct(p_next.get(L,0))}", letter_color(L))
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(5)
    for i,L in enumerate(["F","U","N","K","Y2"]):
        key="Y" if L=="Y2" else L
        with cols[i]: display_tile(key, f"P(next) {pct(p_next.get(key,0))}", letter_color(L))
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(4)
    for i,L in enumerate(["T","I","M","E"]):
        with cols[i]: display_tile(L, f"P(next) {pct(p_next.get(L,0))}", letter_color(L))
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(3)
    for i,B in enumerate(["DISCO","STAYINALIVE","DISCO_VIP"]):
        with cols[i]:
            display_tile("VIP DISCO" if B=="DISCO_VIP" else ("STAYIN'ALIVE" if B=="STAYINALIVE" else "DISCO"),
                         f"P(next) {pct(p_next.get(B,0))}", letter_color(B),
                         height=TILE_H, txt_size=TILE_TXT_BONUS)

# ========== Board + 10 ==========
with tab_board:
    section_header("Ù„ÙˆØ­Ø© Ø§Ù„Ø±Ù‡Ø§Ù† + ØªÙˆÙ‚Ø¹ Ø§Ù„Ø¸Ù‡ÙˆØ± Ø®Ù„Ø§Ù„ 10 Ø¬ÙˆÙ„Ø§Øª")
    st.caption("Ø§Ù„Ù†Ø³Ø¨Ø© Ø£Ø³ÙÙ„ ÙƒÙ„ Ø®Ø§Ù†Ø© Ù‡ÙŠ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø¸Ù‡ÙˆØ± Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ø®Ù„Ø§Ù„ Ø§Ù„Ø¬ÙˆÙ„Ø§Øª Ø§Ù„Ø¹Ø´Ø± Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©.")
    def prob10(seg): return pct(p_at_least_once(p_next.get(seg,0.0), 10))
    c1,c2=st.columns(2)
    with c1: display_tile("1", f"â‰¥1 in 10: {prob10('1')}", letter_color("1"),
                          height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    with c2: display_tile("BAR", f"â‰¥1 in 10: {prob10('BAR')}", letter_color("BAR"),
                          height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(4)
    for i,L in enumerate(["P","L","A","Y"]):
        with cols[i]: display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L),
                                   height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(5)
    for i,L in enumerate(["F","U","N","K","Y"]):
        with cols[i]: display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L if L!="Y" else "Y2"),
                                   height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(4)
    for i,L in enumerate(["T","I","M","E"]):
        with cols[i]: display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L),
                                   height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)
    cols=st.columns(3)
    for i,B in enumerate(["DISCO","STAYINALIVE","DISCO_VIP"]):
        label="VIP DISCO" if B=="DISCO_VIP" else ("STAYIN'ALIVE" if B=="STAYINALIVE" else "DISCO")
        with cols[i]: display_tile(label, f"â‰¥1 in 10: {prob10(B)}", letter_color(B),
                                   height=TILE_H_SMALL, txt_size=TILE_TXT_BONUS, sub_size=TILE_SUB_SMALL)

# ========== Table ==========
with tab_table:
    section_header("ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙƒÙ‡Ù‘Ù†Ø§Øª (10/15/25 Ùˆ Exp in 15)")
    rows=[]
    for s in ORDER:
        p=p_next.get(s,0.0)
        rows.append({
            "Segment": "VIP DISCO" if s=="DISCO_VIP" else ("STAYIN'ALIVE" if s=="STAYINALIVE" else s),
            "â‰¥1 in 10": p_at_least_once(p,10),
            "â‰¥1 in 15": p_at_least_once(p,15),
            "â‰¥1 in 25": p_at_least_once(p,25),
            "Exp in 15": exp_count(p,15),
            "_color": letter_color("Y2" if s=="Y" else s),
        })
    tdf=pd.DataFrame(rows)
    def _fmt(v, col):
        return f"{v*100:.1f}%" if col in {"â‰¥1 in 10","â‰¥1 in 15","â‰¥1 in 25"} else (f"{v:.2f}" if col=="Exp in 15" else v)
    styled = (tdf.drop(columns=["_color"])
                .style.format({c:(lambda v, c=c: _fmt(v,c)) for c in ["â‰¥1 in 10","â‰¥1 in 15","â‰¥1 in 25","Exp in 15"]})
                .apply(lambda s: [f"background-color: {tdf.loc[i,'_color']}; color: white; font-weight:700"
                                  if s.name=="Segment" else "" for i in range(len(s))], axis=0))
    st.dataframe(styled, use_container_width=True)

# ========== Falcon Eye ==========
with tab_falcon:
    section_header("Ø¹ÙŠÙ† Ø§Ù„ØµÙ‚Ø± â€” ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØªØ­Ø°ÙŠØ±Ø§Øª")
    any10=any15=any25=1.0
    for b in BONUS_SEGMENTS:
        pb=p_next.get(b,0.0)
        any10*=(1.0-pb)**10; any15*=(1.0-pb)**15; any25*=(1.0-pb)**25
    any10=1.0-any10; any15=1.0-any15; any25=1.0-any25

    c0,c1,c2=st.columns(3)
    with c0: st.markdown(f"<div style='background:#1565C0;padding:14px;border-radius:14px;font-weight:700;color:white'>ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 10: <span style='float:right'>{pct(any10)}</span></div>", unsafe_allow_html=True)
    with c1: st.markdown(f"<div style='background:#00897B;padding:14px;border-radius:14px;font-weight:700;color:white'>ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 15: <span style='float:right'>{pct(any15)}</span></div>", unsafe_allow_html=True)
    with c2: st.markdown(f"<div style='background:#6A1B9A;padding:14px;border-radius:14px;font-weight:700;color:white'>ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 25: <span style='float:right'>{pct(any25)}</span></div>", unsafe_allow_html=True)

    st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)

    bonus10={b: p_at_least_once(p_next.get(b,0.0),10) for b in BONUS_SEGMENTS}
    p50=sum(bonus10.values())*0.25; p100=sum(bonus10.values())*0.10; pLegend=sum(bonus10.values())*0.04
    d1,d2,d3=st.columns(3)
    with d1: st.markdown(f"<div style='background:#F8E16C;padding:14px;border-radius:14px;font-weight:700'>ğŸ Ø¨ÙˆÙ†Øµ â‰¥ Ã—50 ÙÙŠ 10: <span style='float:right'>{pct(p50)}</span></div>", unsafe_allow_html=True)
    with d2: st.markdown(f"<div style='background:#61C16D;padding:14px;border-radius:14px;font-weight:700;color:white'>ğŸ’ Ø¨ÙˆÙ†Øµ â‰¥ Ã—100 ÙÙŠ 10: <span style='float:right'>{pct(p100)}</span></div>", unsafe_allow_html=True)
    with d3: st.markdown(f"<div style='background:#7C4DFF;padding:14px;border-radius:14px;font-weight:700;color:white'>ğŸš€ Ø¨ÙˆÙ†Øµ Ø£Ø³Ø·ÙˆØ±ÙŠ (+100) ÙÙŠ 10: <span style='float:right'>{pct(pLegend)}</span></div>", unsafe_allow_html=True)

    st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)

    Wmini=min(30,len(df))
    if Wmini>=10:
        tail=df.tail(Wmini); counts=tail["segment"].value_counts(normalize=True)
        meanp=counts.mean(); varp=((counts-meanp)**2).mean()
        if varp>0.005: change_label="High change"; badge="<span style='color:#D32F2F;font-weight:700'>HIGH</span>"
        elif varp>0.002: change_label="Medium change"; badge="<span style='color:#FB8C00;font-weight:700'>MEDIUM</span>"
        else: change_label="Low change"; badge="<span style='color:#2E7D32;font-weight:700'>LOW</span>"
    else:
        change_label="Not enough data"; badge="<span style='color:#999'>N/A</span>"
    st.markdown(f"<div style='background:#1E1E1E;color:#fff;padding:14px;border-radius:12px'>ğŸ” Ø§Ù„ØªÙ‚Ù„Ø¨ Ø§Ù„Ø¹Ø§Ù…: {change_label} â€” {badge}</div>", unsafe_allow_html=True)

    st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)

    def binom_tail_ge_k(n,p,k):
        p=max(0.0,min(1.0,float(p))); total=0.0
        for r in range(0,k): total += math.comb(n,r)*(p**r)*((1-p)**(n-r))
        return 1.0-total
    p1_next=p_next.get("1",0.0); p1_in15=p_at_least_once(p1_next,15)
    color15="#D32F2F" if p1_in15>0.85 else "#37474F"
    st.markdown(f"<div style='background:{color15};color:#fff;padding:14px;border-radius:12px'>âš ï¸ ØªØ­Ø°ÙŠØ±: Ø³ÙŠØ·Ø±Ø© Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø±Ù‚Ù… 1 Ø®Ù„Ø§Ù„ 15 Ø³Ø¨ÙÙ† â€” P(â‰¥1 Ø®Ù„Ø§Ù„ 15) = {pct(p1_in15)}</div>", unsafe_allow_html=True)
    p1_ge3_in10 = binom_tail_ge_k(10, p1_next, 3)
    st.markdown(f"<div style='background:#B71C1C;color:#fff;padding:14px;border-radius:12px'>ğŸ›‘ ØªÙ†Ø¨ÙŠÙ‡ Ø­Ø§Ø¯: Ø§Ø­ØªÙ…Ø§Ù„ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø±Ù‚Ù… <b>1</b> Ø«Ù„Ø§Ø« Ù…Ø±Ø§Øª Ø£Ùˆ Ø£ÙƒØ«Ø± Ø®Ù„Ø§Ù„ 10 Ø³Ø¨ÙÙ† = <b>{pct(p1_ge3_in10)}</b> â€” ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ù…Ø¤Ù‚Øª.</div>", unsafe_allow_html=True)

# ========== Ø£Ø³ÙÙ„ Ø§Ù„ØµÙØ­Ø© ==========
with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¢Ø®Ø± Ù†Ø§ÙØ°Ø©)"):
    st.dataframe(df.tail(50), use_container_width=True)

# ---------- ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø¯Ø§Ø®Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ----------
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ› ï¸ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
model_path_input = st.sidebar.text_input("Ù…Ø³Ø§Ø± Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", value="models/pattern_model.pkl")
with st.sidebar.expander("Ù…Ù„Ø®Øµ Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"):
    st.write(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ù…ÙŠØ§Øª: **{len(df)}**"); st.write("Ø£Ø¹Ù…Ø¯Ø©:", list(df.columns)); st.dataframe(df.tail(10), use_container_width=True)

def train_and_save_model(df, path, horizon, temperature, decay_half_life, bonus_boost):
    p_next, _ = recency_softmax_probs(df, horizon=horizon, temperature=temperature, decay_half_life=decay_half_life, bonus_boost=bonus_boost)
    model = {"type":"recency_softmax","p_next":p_next,"meta":{
        "horizon":horizon,"temperature":temperature,"half_life":decay_half_life,"bonus_boost":bonus_boost,
        "trained_on_rows":int(len(df)),"trained_at":datetime.utcnow().isoformat()+"Z"}}
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path,"wb") as f: pickle.dump(model,f)
    return model

if st.sidebar.button("ğŸ’¾ Ø¯Ø±Ù‘ÙØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¢Ù†", use_container_width=True):
    if df.empty: st.sidebar.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨.")
    else:
        try:
            _ = train_and_save_model(df, model_path_input, horizon, temperature, decay_half_life, bonus_boost)
            st.sidebar.success(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {model_path_input}")
            with open(model_path_input,"rb") as fh:
                st.sidebar.download_button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", fh.read(), file_name="pattern_model.pkl", mime="application/octet-stream", use_container_width=True)
        except Exception as e:
            st.sidebar.error(f"ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")

st.sidebar.caption("Ø¨Ø¹Ø¯ ØªØ­Ù…ÙŠÙ„ pattern_model.pkl Ø§Ø±ÙØ¹Ù‡ Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ models/ ÙÙŠ GitHub Ù„ÙŠØ¨Ù‚Ù‰ Ø¯Ø§Ø¦Ù…Ù‹Ø§.")
