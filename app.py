# app.py â€” Funky Brain LIVE (V3)
# - ÙŠÙ‚Ù€Ø±Ø£ Ù…Ù† data/combined_spins.csv Ø£Ùˆ Ù…Ù† Ø±ÙØ¹ Ù…Ù„Ù / Google Sheets
# - Ù†Ù…ÙˆØ°Ø¬ Recency+Softmax Ù…Ø¹ Bonus boost
# - ØªØ¨ÙˆÙŠØ¨Ø§Øª: Tiles / Board + 10 / Table / Falcon Eye
# - ØªÙ†Ø¨ÙŠÙ‡ Ø¹ÙŠÙ† Ø§Ù„ØµÙ‚Ø±: Ø§Ø­ØªÙ…Ø§Ù„ ØªÙƒØ±Ø§Ø± "1" â‰¥ 3 Ù…Ø±Ø§Øª ÙÙŠ 10 Ø±Ù…ÙŠØ§Øª
# - Ø²Ø± Ø¯Ø§Ø®Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„Ø¯Ù…Ø¬ Ù…Ù„ÙØ§Øª data/spins_cleaned_*.csv(xlsx) Ø¥Ù„Ù‰ combined_spins.csv
# - Ù…Ø¹Ø§ÙŠÙ†Ø© ÙÙˆØ±ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ
# - Ø®Ù„ÙÙŠØ© "Ø¬Ùˆ Ø§Ù„Ø¯ÙŠØ³ÙƒÙˆ"
# - ØªÙ†Ø¨ÙŠÙ‡ Ø§ØªØ¬Ø§Ù‡ RTP + ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ØµÙˆØªÙŠØ© Ù„Ù„Ø¨ÙˆÙ†Øµ Ø§Ù„ÙƒØ¨ÙŠØ± Ùˆ"Ø¹ÙŠÙ† Ø§Ù„ØµÙ‚Ø±"

import os
import math
import base64
import pandas as pd
import numpy as np
import streamlit as st
from datetime import datetime, timedelta

# ===== Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯ÙˆØ§Ù„Ù‘Ùƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¥Ù† ÙˆÙØ¬Ø¯Øª (Ù„Ø§ Ù†ÙƒØ³Ø± Ø´ÙŠØ¡) =====
_HAS_CORE = False
try:
    from funkybrain_core import normalize_df, compute_probs, board_model
    _HAS_CORE = True
except Exception:
    _HAS_CORE = False

# ------------------------ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø© ------------------------
st.set_page_config(page_title="Funky Brain LIVE", layout="wide")

# Ø®Ù„ÙÙŠØ© "Ø¬Ùˆ Ø§Ù„Ø¯ÙŠØ³ÙƒÙˆ"
st.markdown("""
<style>
/* Ø®Ù„ÙÙŠØ© ÙƒØ±Ø© Ø¯ÙŠØ³ÙƒÙˆ Ø®ÙÙŠÙØ© */
[data-testid="stAppViewContainer"]{
  background: radial-gradient( circle at 20% 20%, rgba(255,255,255,.08), rgba(0,0,0,0) 40% ),
              radial-gradient( circle at 80% 30%, rgba(255,255,255,.06), rgba(0,0,0,0) 40% ),
              url('https://images.unsplash.com/photo-1545239351-1141bd82e8a6?q=80&w=1200&auto=format&fit=crop') center/cover no-repeat fixed;
}
[data-testid="stHeader"] {background: transparent;}
/* Ø¨Ø·Ø§Ù‚Ø§Øª Ø¹Ø§Ø¦Ù…Ø© */
.block-container{backdrop-filter: blur(2px);}
</style>
""", unsafe_allow_html=True)

st.title("ğŸª© Funky Brain â€” LIVE (V3)")

# Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
DATA_DIR = "data"
REPO_COMBINED_PATH = os.path.join(DATA_DIR, "combined_spins.csv")

# Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª
COLORS = {
    "ONE": "#F4D36B", "BAR": "#5AA64F",
    "ORANGE": "#E7903C", "PINK": "#C85C8E", "PURPLE": "#9A5BC2",
    "STAYINALIVE": "#4FC3D9", "DISCO": "#314E96", "DISCO_VIP": "#B03232",
}
BONUS_SEGMENTS = {"DISCO","STAYINALIVE","DISCO_VIP","BAR"}
ALL_SEGMENTS = {
    "1","BAR","P","L","A","Y","F","U","N","K","Y","T","I","M","E","DISCO","STAYINALIVE","DISCO_VIP"
}
ORDER = ["1","BAR","P","L","A","Y","F","U","N","K","Y","T","I","M","E","DISCO","STAYINALIVE","DISCO_VIP"]

# Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª (ØªØµØºÙŠØ± Ù…ØªÙˆØ§Ø²Ù†)
TILE_H=86; TILE_TXT=32; TILE_SUB=12
TILE_H_SMALL=78; TILE_TXT_SMALL=28; TILE_SUB_SMALL=11
TILE_TXT_BONUS=18

# ------------------------ ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© ------------------------
def pct(x: float) -> str:
    try:
        return f"{float(x)*100:.1f}%"
    except Exception:
        return "0.0%"

def p_at_least_once(p: float, n: int) -> float:
    return 1.0 - (1.0 - float(p))**int(n)

def exp_count(p: float, n: int) -> float:
    return float(n) * float(p)

def letter_color(letter: str) -> str:
    if letter in {"1","ONE"}: return COLORS["ONE"]
    if letter=="BAR": return COLORS["BAR"]
    if letter in {"P","L","A","Y"}: return COLORS["ORANGE"]
    if letter in {"F","U","N","K","Y"}: return COLORS["PINK"]
    if letter in {"T","I","M","E"}: return COLORS["PURPLE"]
    if letter=="STAYINALIVE": return COLORS["STAYINALIVE"]
    if letter=="DISCO": return COLORS["DISCO"]
    if letter=="DISCO_VIP": return COLORS["DISCO_VIP"]
    return "#444"

def display_tile(label, subtext, bg, height=TILE_H, radius=16, txt_size=TILE_TXT, sub_size=TILE_SUB):
    st.markdown(
        f"""
        <div style="background:{bg};color:white;border-radius:{radius}px;height:{height}px;
                    display:flex;flex-direction:column;align-items:center;justify-content:center;font-weight:700; box-shadow:0 4px 16px rgba(0,0,0,.20);">
            <div style="font-size:{txt_size}px;line-height:1">{label}</div>
            <div style="font-size:{sub_size}px;opacity:.95;margin-top:2px">{subtext}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

def section_header(title):
    st.markdown(
        f"<div style='font-size:20px;font-weight:700;margin:6px 0 10px'>{title}</div>",
        unsafe_allow_html=True,
    )

# ---------- Ù…Ù†Ø¸Ù Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ ----------
def clean_df(df: pd.DataFrame) -> pd.DataFrame:
    """
    ÙŠØªÙˆÙ‚Ø¹ df ÙÙŠÙ‡ ts/segment/multiplier Ø£Ùˆ Ø®Ø§Ù… ÙŠØ­ÙˆÙŠ Ø£Ø¹Ù…Ø¯Ø© Ø¨Ø¯ÙŠÙ„Ø©.
    - ÙŠØ­Ø§ÙˆÙ„ Ø¥ÙŠØ¬Ø§Ø¯ ts ÙÙŠ Ø£Ø¹Ù…Ø¯Ø© Ø´Ø§Ø¦Ø¹Ø© (ts, time, timestamp, date, created_at ...)
    - ÙŠØ­Ø§ÙˆÙ„ Ø¥ÙŠØ¬Ø§Ø¯ segment Ù…Ø¨Ø§Ø´Ø±Ø© Ø£Ùˆ Ù…Ù† Ù…Ø³Ø§Ø± ØµÙˆØ±Ø© ÙŠÙ†ØªÙ‡ÙŠ Ø¨Ù€ .../<token>.png
    - multiplier Ø¥Ù„Ù‰ "12X"
    """
    data = df.copy()

    # ----- ts -----
    ts_cols = [c for c in data.columns if str(c).strip().lower() in
               {"ts","time","timestamp","datetime","date","created_at"}]
    if ts_cols:
        tsc = ts_cols[0]
        data["ts"] = pd.to_datetime(data[tsc], errors="coerce")
    else:
        # Ø¥Ù† Ù„Ù… ÙŠÙˆØ¬Ø¯ØŒ Ù†Ø­Ø§ÙˆÙ„ Ù…Ù† Ù†Øµ Ø·ÙˆÙŠÙ„ ÙŠØ­ÙˆÙŠ ÙˆÙ‚ØªÙ‹Ø§
        # ÙˆØ¥Ù„Ø§ Ù†ÙˆÙ„Ù‘Ø¯ ØªØ³Ø§ÙˆÙŠÙ‹Ø§ Ø¨ÙÙˆØ§ØµÙ„ Ø¯Ù‚ÙŠÙ‚Ø©
        data["ts"] = pd.to_datetime(data.iloc[:,0], errors="coerce")
        if data["ts"].isna().all():
            base = datetime.utcnow() - timedelta(minutes=len(data))
            data["ts"] = [base + timedelta(minutes=i) for i in range(len(data))]

    # ----- segment -----
    if "segment" not in data.columns:
        data["segment"] = None
    # Ù„Ùˆ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ URL/IMG Ù†Ø³ØªØ®Ø±ÙØ¬ Ù…Ù† Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø§Ø³Ù… Ø¨Ù„Ø§ Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯
    url_like_cols = [c for c in data.columns if any(x in str(c).lower() for x in ["img","image","url","src","icon","path"])]
    def _from_url(val: str) -> str|None:
        if not isinstance(val,str) or "." not in val: return None
        token = val.split("/")[-1].split(".")[0].strip().upper()
        # Ø®Ø±Ø§Ø¦Ø· Ø´Ø§Ø¦Ø¹Ø©
        maps = {
            "1":"1","ONE":"1","BAR":"BAR","DISCO":"DISCO","DISCOVIP":"DISCO_VIP","DISCO_VIP":"DISCO_VIP",
            "STAYINALIVE":"STAYINALIVE",
            "P":"P","L":"L","A":"A","Y":"Y","F":"F","U":"U","N":"N","K":"K","T":"T","I":"I","M":"M","E":"E",
        }
        # Ø­Ø§Ù„Ø§Øª Ù…Ø«Ù„ funky-time/Y.png, barstatspin.png...
        token = token.replace("BARSTATSPIN","BAR").replace("DISCOVIP","DISCO_VIP").replace("VIPDISCO","DISCO_VIP")
        return maps.get(token, None)

    if data["segment"].isna().any() and url_like_cols:
        s = data["segment"].copy()
        for c in url_like_cols:
            s = s.fillna(data[c].map(_from_url))
        data["segment"] = s

    # Ø£ÙŠ Ù‚ÙŠÙ… Ù…Ø¬Ù‡ÙˆÙ„Ø© Ù†ØªØ±ÙƒÙ‡Ø§ UNKNOWN (ÙˆÙ„Ø§ Ù†Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ)
    data["segment"] = data["segment"].astype(str).str.strip().str.upper().replace({"NONE":"UNKNOWN","NAN":"UNKNOWN","":"UNKNOWN"})

    # ----- multiplier -----
    mult_cols = [c for c in data.columns if str(c).strip().lower() in {"multiplier","multi","x","factor","payout"}]
    if mult_cols:
        mc = mult_cols[0]
        mult = data[mc].astype(str).str.extract(r"(\d+)", expand=False)
    else:
        # Ù†Ø­Ø§ÙˆÙ„ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø·ÙˆÙŠÙ„ (Ù‚Ø¯ ÙŠÙƒÙˆÙ† "â€¦ 25X â€¦")
        mult = data.apply(lambda r: pd.Series(str(r.astype(str).to_string())).str.extract(r"(\d+)[xX]"), axis=1)[0]
    mult = mult.fillna("1").astype(int).clip(lower=1, upper=500).astype(str) + "X"
    data["multiplier"] = mult

    # Ø¥Ø³Ù‚Ø§Ø· ts Ø§Ù„ÙØ§Ø±Øº ÙÙ‚Ø·
    data = data.dropna(subset=["ts"]).copy()
    data["ts"] = pd.to_datetime(data["ts"], errors="coerce")

    # ØªØ±ØªÙŠØ¨
    data = data.sort_values("ts")

    # Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    out = data[["ts","segment","multiplier"]].reset_index(drop=True)
    return out

# ---------- Ù…Ø¯Ù…Ø¬ Ø¯Ø§Ø®Ù„ÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ----------
def combine_inside_streamlit(raw_file=None) -> tuple[int, str, pd.DataFrame|None]:
    """
    - ÙŠÙ‚Ø±Ø£ ÙƒÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªØ¨Ø¯Ø£ Ø¨Ù€ spins_cleaned ÙÙŠ Ù…Ø¬Ù„Ø¯ data/ (CSV/XLSX/XLS)
    - Ù„Ùˆ raw_file Ù…ÙÙ…Ø±Ù‘Ø±: ÙŠÙ†Ø¸ÙÙ‡ ÙˆÙŠØ¶Ù…Ù‡ Ø£ÙŠØ¶Ù‹Ø§
    - ÙŠØ¯Ù…Ø¬ Ø¥Ù„Ù‰ data/combined_spins.csv
    - ÙŠØ±Ø¬Ø¹ (Ø¹Ø¯Ø¯_Ø§Ù„ØµÙÙˆÙ, Ø±Ø³Ø§Ù„Ø©, Ù…Ø¹Ø§ÙŠÙ†Ø©_cleaned Ø¥Ù† ÙˆÙØ¬Ø¯Øª Ù„Ù„Ù€ raw)
    """
    os.makedirs(DATA_DIR, exist_ok=True)
    paths = []
    for name in os.listdir(DATA_DIR):
        low = name.lower()
        if low.startswith("spins_cleaned") and (low.endswith(".csv") or low.endswith(".xlsx") or low.endswith(".xls")):
            paths.append(os.path.join(DATA_DIR, name))

    frames = []
    # Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¬Ù„Ø¯
    for p in sorted(paths):
        try:
            if p.lower().endswith(".csv"):
                df = pd.read_csv(p)
            else:
                df = pd.read_excel(p)
            frames.append(clean_df(df))
        except Exception as e:
            st.warning(f"ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù…Ù„Ù {os.path.basename(p)} Ø¨Ø³Ø¨Ø¨: {e}")

    # Ù…Ù„Ù Ø®Ø§Ù… Ù…Ø±ÙÙˆØ¹ Ø§Ù„Ø¢Ù† (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
    cleaned_preview = None
    if raw_file is not None:
        try:
            if raw_file.name.lower().endswith(".csv"):
                rdf = pd.read_csv(raw_file)
            else:
                rdf = pd.read_excel(raw_file)
            cleaned_preview = clean_df(rdf)
            frames.append(cleaned_preview)
        except Exception as e:
            return 0, f"ÙØ´Ù„ ØªÙ†Ø¸ÙŠÙ/Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø®Ø§Ù…: {e}", None

    if not frames:
        return 0, "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© Ù„Ù„Ø¯Ù…Ø¬.", cleaned_preview

    big = pd.concat(frames, ignore_index=True)
    # Ø¥Ø²Ø§Ù„Ø© ØªÙƒØ±Ø§Ø±Ø§Øª
    big = big.drop_duplicates(subset=["ts","segment","multiplier"]).sort_values("ts").reset_index(drop=True)
    big.to_csv(REPO_COMBINED_PATH, index=False, encoding="utf-8")
    return len(big), f"ØªÙ… Ø§Ù„Ø¯Ù…Ø¬ ÙÙŠ {REPO_COMBINED_PATH} â€” Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙÙˆÙ: {len(big):,}", cleaned_preview

# ---------- Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (repo / upload / sheets) ----------
@st.cache_data(show_spinner=False)
def load_data(file, sheet_url, window, use_repo_file=False, repo_path=REPO_COMBINED_PATH):
    """
    ÙŠØ­Ù…Ù‘Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†:
    - Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ data/combined_spins.csv (Ø¥Ù† Ø·ÙÙ„Ø¨ ÙˆÙ…ÙˆØ¬ÙˆØ¯)
    - Ù…Ù„Ù Ù…Ø±ÙÙˆØ¹ CSV/Excel
    - Google Sheets (Ù†Ø­ÙˆÙ‘Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ø¹Ø±Ø¶ Ø¥Ù„Ù‰ export?format=csv ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§)
    Ø«Ù… ÙŠØ±Ø¬Ø¹ Ø¢Ø®Ø± window ØµÙÙˆÙ Ù…Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: ts, segment, multiplier
    """
    df = None

    # (Ø£) Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
    if use_repo_file and os.path.exists(repo_path):
        try:
            df = pd.read_csv(repo_path)
        except Exception as e:
            st.warning(f"ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© {repo_path}: {e}")

    # (Ø¨) Ù…Ù„Ù Ù…Ø±ÙÙˆØ¹
    if df is None and file is not None:
        try:
            if file.name.lower().endswith(".csv"):
                df = pd.read_csv(file)
            else:
                df = pd.read_excel(file)
        except Exception as e:
            st.error(f"ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
            return pd.DataFrame(columns=["ts","segment","multiplier"])

    # (Ø¬) Google Sheets -> CSV
    if df is None and sheet_url:
        url = sheet_url.strip()
        if "docs.google.com/spreadsheets" in url and "export?format=csv" not in url:
            try:
                gid = url.split("gid=")[-1]
            except Exception:
                gid = "0"
            doc_id = url.split("/d/")[1].split("/")[0]
            url = f"https://docs.google.com/spreadsheets/d/{doc_id}/export?format=csv&gid={gid}"
        try:
            df = pd.read_csv(url)
        except Exception as e:
            st.error(f"ØªØ¹Ø°Ù‘Ø± ØªØ­Ù…ÙŠÙ„ Google Sheets: {e}")
            return pd.DataFrame(columns=["ts","segment","multiplier"])

    if df is None:
        return pd.DataFrame(columns=["ts","segment","multiplier"])

    try:
        df = clean_df(df)
    except Exception as e:
        st.error(f"ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ØºÙŠØ± ØµØ§Ù„Ø­: {e}")
        return pd.DataFrame(columns=["ts","segment","multiplier"])

    # Ù‚Øµ Ø§Ù„Ù†Ø§ÙØ°Ø©
    if len(df) > window:
        df = df.tail(window).copy()

    return df.reset_index(drop=True)

# -------- Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª: Recency + Softmax + Bonus boost --------
def recency_softmax_probs(df, horizon=10, temperature=1.6, decay_half_life=60, bonus_boost=1.15):
    """Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ ØªØ±Ø¬ÙŠØ­ Ø­Ø¯Ø§Ø«Ø© Ø£ÙØ³Ù‘ÙŠ + Softmax Ø¨Ø­Ø±Ø§Ø±Ø© + ØªØ¹Ø²ÙŠØ² Ø¨Ø³ÙŠØ· Ù„Ù„Ø¨ÙˆÙ†Øµ."""
    try:
        dfx = df.copy()
        segs = list(ALL_SEGMENTS)
        n = len(dfx)

        if n == 0:
            vec = np.ones(len(segs), dtype=float)
        else:
            ages = np.arange(n, 0, -1)               # Ø§Ù„Ø£Ø­Ø¯Ø« Ø¹Ù…Ø±Ù‡ 1
            half = max(int(decay_half_life), 1)
            w = np.power(0.5, (ages-1)/half)         # ÙˆØ²Ù† Ø£Ø³ÙŠ
            w = w / w.sum()

            counts = {s: 0.0 for s in segs}
            for seg, wt in zip(dfx["segment"], w):
                if seg in counts:
                    counts[seg] += wt
            vec = np.array([counts[s] for s in segs], dtype=float)

        # ØªØ¹Ø²ÙŠØ² Ù„Ù„Ø¨ÙˆÙ†Øµ
        for i, s in enumerate(segs):
            if s in BONUS_SEGMENTS:
                vec[i] *= float(bonus_boost)

        # softmax Ø¨Ø¯Ø±Ø¬Ø© Ø­Ø±Ø§Ø±Ø©
        if vec.sum() <= 0:
            vec[:] = 1.0
        x = vec / (vec.std() + 1e-9)
        x = x / max(float(temperature), 1e-6)
        z = np.exp(x - x.max())
        p_next = z / z.sum()

        probs = dict(zip(segs, p_next))
        p_in10 = {s: p_at_least_once(probs[s], horizon) for s in segs}
        return probs, p_in10
    except Exception:
        # Fallback Ø¨Ø³ÙŠØ· (ØªÙƒØ±Ø§Ø±Ø§Øª)
        counts = df["segment"].value_counts()
        segs = list(ALL_SEGMENTS)
        vec = np.array([counts.get(s, 0) for s in segs], dtype=float)
        if vec.sum() == 0:
            vec[:] = 1.0
        z = np.exp((vec - vec.mean()) / (vec.std() + 1e-6))
        p = z / z.sum()
        probs = dict(zip(segs, p))
        p_in10 = {s: p_at_least_once(probs[s], horizon) for s in segs}
        return probs, p_in10

def get_probs(df, horizon=10, temperature=1.6, decay_half_life=60, bonus_boost=1.15, use_model=False, model_path="models/pattern_model.pkl"):
    """ÙŠØ­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯ÙˆØ§Ù„Ù‘Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø£Ùˆ Ù…Ù„Ù Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¯Ø±Ù‘Ø¨ØŒ ÙˆØ¥Ù† ÙØ´Ù„ ÙŠØ³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ±Ø¬ÙŠØ­/Ø§Ù„Ø³ÙˆÙØªÙ…Ø§ÙƒØ³."""
    if use_model:
        try:
            import pickle
            with open(model_path, "rb") as f:
                obj = pickle.load(f)
            if isinstance(obj, dict) and "p_next" in obj:
                p_next = obj["p_next"]
                p_in10 = {s: p_at_least_once(p_next.get(s,0.0), horizon) for s in ALL_SEGMENTS}
                return p_next, p_in10
        except Exception:
            pass

    if _HAS_CORE:
        try:
            dfn = normalize_df(df)
            comp = compute_probs(dfn, horizon=horizon)
            p_next = comp.get("p_next", {})
            p_in10 = comp.get("p_in10", {})
            if len(p_next) == 0 or len(p_in10) == 0:
                raise ValueError("Empty core probs -> use recency/softmax")
            return p_next, p_in10
        except Exception:
            pass

    return recency_softmax_probs(
        df,
        horizon=horizon,
        temperature=temperature,
        decay_half_life=decay_half_life,
        bonus_boost=bonus_boost,
    )

# ------------------------ Ø£ØµÙˆØ§Øª (base64) ------------------------
# Ø¨ÙŠØ¨ Ù‚ØµÙŠØ±
_BEEP = b'UklGRiQAAABXQVZFZm10IBAAAAABAAEAESsAACJWAAACABYAAAACAAABaW1hAA=='
def play_beep():
    src = "data:audio/wav;base64," + base64.b64encode(base64.b64decode(_BEEP)).decode()
    st.markdown(f"""
    <audio autoplay="true">
      <source src="{src}" type="audio/wav">
    </audio>
    """, unsafe_allow_html=True)

# ------------------------ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ------------------------
with st.sidebar:
    st.subheader("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    window = st.slider("Window size (spins)", 50, 300, 120, step=10)
    horizon = st.slider("ØªÙˆÙ‚Ø¹ Ø¹Ù„Ù‰ ÙƒÙ… Ø¬ÙˆÙ„Ø©ØŸ", 5, 20, 10, step=1)
    st.write("---")
    st.subheader("ğŸ›ï¸ Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤ (Recency/Softmax)")
    temperature = st.slider("Temperature (ØªØ±ÙƒÙŠØ² Ø§Ù„Ø³ÙˆÙØª-Ù…Ø§ÙƒØ³)", 1.0, 2.5, 1.6, 0.1)
    decay_half_life = st.slider("Half-life (ØªØ±Ø¬ÙŠØ­ Ø§Ù„Ø­Ø¯Ø§Ø«Ø©)", 20, 120, 60, 5)
    bonus_boost = st.slider("ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø¨ÙˆÙ†Øµ", 1.00, 1.40, 1.15, 0.05)
    st.write("---")
    st.subheader("ğŸ“¥ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    use_repo_combined = st.toggle("Ø§Ø³ØªØ®Ø¯Ù… Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ data/combined_spins.csv", value=True)
    sheet_url = st.text_input("Ø±Ø§Ø¨Ø· Google Sheets (Ù…ÙØ¶Ù‘Ù„ CSV export)", value="")
    upload = st.file_uploader("â€¦Ø£Ùˆ Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV/Excel", type=["csv","xlsx","xls"])

    st.write("---")
    st.subheader("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø®Ø§Ù… + Ø¯Ù…Ø¬")
    if upload is not None:
        if st.button("ğŸª› ØªÙ†Ø¸ÙŠÙ + Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ combined_spins.csv", use_container_width=True):
            rows, msg, cleaned_preview = combine_inside_streamlit(raw_file=upload)
            if rows > 0:
                st.success(msg)
                if cleaned_preview is not None and not cleaned_preview.empty:
                    st.caption("ğŸ“„ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ (Ø£ÙˆÙ„/Ø¢Ø®Ø± 5):")
                    st.dataframe(pd.concat([cleaned_preview.head(5), cleaned_preview.tail(5)]), use_container_width=True)
                # Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØ§Ø´ Ø­ØªÙ‰ ØªØ¸Ù‡Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
                load_data.clear()
                st.experimental_rerun()
            else:
                st.error(msg)
    else:
        st.caption("Ø£Ø±ÙÙ‚ Ù…Ù„Ù Ø®Ø§Ù… Ø¥Ù† Ø£Ø±Ø¯Øª ØªÙ†Ø¸ÙŠÙÙ‡ Ø§Ù„Ø¢Ù†.")

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬
    if os.path.exists(REPO_COMBINED_PATH):
        with open(REPO_COMBINED_PATH, "rb") as f:
            st.download_button("â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ combined_spins.csv", f.read(), file_name="combined_spins.csv", mime="text/csv")

    st.write("---")
    st.subheader("ğŸ¤– Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ¹Ù„Ù‘ÙÙ… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    use_trained_model = st.toggle("Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ØªØ¹Ù„Ù‘Ù… Ø¥Ù† ÙˆØ¬Ø¯", value=False)
    model_path_ui = st.text_input("Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", value="models/pattern_model.pkl")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¯Ø§ØªØ§
df = load_data(
    upload if not use_repo_combined else None, sheet_url, window,
    use_repo_file=use_repo_combined, repo_path=REPO_COMBINED_PATH
)
if df.empty:
    st.info("Ø£Ø¶Ù Ù…ØµØ¯Ø± Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­ ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: ts, segment, multiplier")
    st.stop()

# Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª
p_next, p_in10 = get_probs(
    df,
    horizon=horizon,
    temperature=temperature,
    decay_half_life=decay_half_life,
    bonus_boost=bonus_boost,
    use_model=use_trained_model,
    model_path=model_path_ui
)

# ---------------- RTP Trend (ØµØ¹ÙˆØ¯/Ù‡Ø¨ÙˆØ·) ----------------
def _to_num(mult_str: str) -> float:
    try:
        return float(str(mult_str).lower().replace("x",""))
    except: return 1.0

rtp_recent_window = min(60, len(df))
baseline_window = min(300, len(df))
recent_avg = df.tail(rtp_recent_window)["multiplier"].map(_to_num).mean()
baseline_avg = df.tail(baseline_window)["multiplier"].map(_to_num).mean()
trend = (recent_avg - baseline_avg) / (baseline_avg + 1e-9)
if trend > 0.07:
    rtp_msg = f"â¬†ï¸ RTP ÙŠØµØ¹Ø¯ (+{trend*100:.1f}%)"; rtp_color = "#2E7D32"
elif trend < -0.07:
    rtp_msg = f"â¬‡ï¸ RTP ÙŠÙ†Ø²Ù„ ({trend*100:.1f}%)"; rtp_color = "#C62828"
else:
    rtp_msg = f"â†”ï¸ RTP Ù…Ø³ØªÙ‚Ø± (+{trend*100:.1f}%)"; rtp_color = "#6D4C41"

st.markdown(
    f"<div style='background:{rtp_color};color:#fff;padding:10px 14px;border-radius:10px;font-weight:700;margin-bottom:6px'>"
    f"{rtp_msg}</div>", unsafe_allow_html=True
)

# ØªØ¨ÙˆÙŠØ¨Ø§Øª: Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª + Ø§Ù„Ù„ÙˆØ­Ø© + Ø§Ù„Ø¬Ø¯ÙˆÙ„ + Ø¹ÙŠÙ† Ø§Ù„ØµÙ‚Ø±
tab_tiles, tab_board, tab_table, tab_falcon = st.tabs(
    ["ğŸ›ï¸ Tiles", "ğŸ¯ Board + 10 Spins", "ğŸ“Š Table", "ğŸ¦… Falcon Eye"]
)

# ========== ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª ==========
with tab_tiles:
    section_header("Ù„ÙˆØ­Ø© Ø§Ù„Ø¨Ù„Ø§Ø·Ø§Øª (Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØµØµØ©)")

    c1, c2 = st.columns(2)
    with c1:
        display_tile("1", f"P(next) {pct(p_next.get('1', 0))}", letter_color("1"))
    with c2:
        display_tile("BAR", f"P(next) {pct(p_next.get('BAR', 0))}", letter_color("BAR"), txt_size=30)

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(4)
    for i, L in enumerate(["P","L","A","Y"]):
        with cols[i]:
            display_tile(L, f"P(next) {pct(p_next.get(L, 0))}", letter_color(L))

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(5)
    for i, L in enumerate(["F","U","N","K","Y"]):   # â† Ø­Ø°Ù Y Ø§Ù„Ù…ÙƒØ±Ø± (Ù„Ù… Ù†Ø¹Ø¯ Ù†Ø³ØªØ®Ø¯Ù… Y2)
        with cols[i]:
            display_tile(L, f"P(next) {pct(p_next.get(L, 0))}", letter_color(L))

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(4)
    for i, L in enumerate(["T","I","M","E"]):
        with cols[i]:
            display_tile(L, f"P(next) {pct(p_next.get(L, 0))}", letter_color(L))

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(3)
    for i, B in enumerate(["DISCO","STAYINALIVE","DISCO_VIP"]):
        with cols[i]:
            display_tile(
                "VIP DISCO" if B=="DISCO_VIP" else ("STAYIN'ALIVE" if B=="STAYINALIVE" else "DISCO"),
                f"P(next) {pct(p_next.get(B, 0))}",
                letter_color(B),
                height=TILE_H, txt_size=TILE_TXT_BONUS
            )

# ========== ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ù„ÙˆØ­Ø© + 10 ==========
with tab_board:
    section_header("Ù„ÙˆØ­Ø© Ø§Ù„Ø±Ù‡Ø§Ù† + ØªÙˆÙ‚Ø¹ Ø§Ù„Ø¸Ù‡ÙˆØ± Ø®Ù„Ø§Ù„ 10 Ø¬ÙˆÙ„Ø§Øª")
    st.caption("Ø§Ù„Ù†Ø³Ø¨Ø© Ø£Ø³ÙÙ„ ÙƒÙ„ Ø®Ø§Ù†Ø© Ù‡ÙŠ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø¸Ù‡ÙˆØ± Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ø®Ù„Ø§Ù„ Ø§Ù„Ø¬ÙˆÙ„Ø§Øª Ø§Ù„Ø¹Ø´Ø± Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©.")

    def prob10(seg): return pct(p_at_least_once(p_next.get(seg, 0.0), 10))

    c1, c2 = st.columns(2)
    with c1:
        display_tile("1", f"â‰¥1 in 10: {prob10('1')}", letter_color("1"),
                     height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)
    with c2:
        display_tile("BAR", f"â‰¥1 in 10: {prob10('BAR')}", letter_color("BAR"),
                     height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(4)
    for i, L in enumerate(["P","L","A","Y"]):
        with cols[i]:
            display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L),
                         height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(5)
    for i, L in enumerate(["F","U","N","K","Y"]):
        with cols[i]:
            display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L),
                         height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(4)
    for i, L in enumerate(["T","I","M","E"]):
        with cols[i]:
            display_tile(L, f"â‰¥1 in 10: {prob10(L)}", letter_color(L),
                         height=TILE_H_SMALL, txt_size=TILE_TXT_SMALL, sub_size=TILE_SUB_SMALL)

    st.markdown("<div style='height:6px'></div>", unsafe_allow_html=True)

    cols = st.columns(3)
    for i, B in enumerate(["DISCO","STAYINALIVE","DISCO_VIP"]):
        label = "VIP DISCO" if B=="DISCO_VIP" else ("STAYIN'ALIVE" if B=="STAYINALIVE" else "DISCO")
        with cols[i]:
            display_tile(label, f"â‰¥1 in 10: {prob10(B)}", letter_color(B),
                         height=TILE_H_SMALL, txt_size=TILE_TXT_BONUS, sub_size=TILE_SUB_SMALL)

# ========== ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ==========
with tab_table:
    section_header("ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙƒÙ‡Ù‘Ù†Ø§Øª (10/15/25 Ùˆ Exp in 15)")
    rows = []
    for s in ORDER:
        p = p_next.get(s, 0.0)
        rows.append({
            "Segment": "VIP DISCO" if s=="DISCO_VIP" else ("STAYIN'ALIVE" if s=="STAYINALIVE" else s),
            "â‰¥1 in 10": p_at_least_once(p, 10),
            "â‰¥1 in 15": p_at_least_once(p, 15),
            "â‰¥1 in 25": p_at_least_once(p, 25),
            "Exp in 15": exp_count(p, 15),
            "_color": letter_color(s),
        })
    tdf = pd.DataFrame(rows)

    def _fmt(v, col):
        return f"{v*100:.1f}%" if col in {"â‰¥1 in 10","â‰¥1 in 15","â‰¥1 in 25"} else (f"{v:.2f}" if col=="Exp in 15" else v)

    styled = (
        tdf.drop(columns=["_color"])
           .style.format({c: (lambda v, c=c: _fmt(v, c)) for c in ["â‰¥1 in 10","â‰¥1 in 15","â‰¥1 in 25","Exp in 15"]})
           .apply(lambda s: [f"background-color: {tdf.loc[i,'_color']}; color: white; font-weight:700"
                             if s.name=="Segment" else "" for i in range(len(s))], axis=0)
    )
    st.dataframe(styled, use_container_width=True)

# ========== ØªØ¨ÙˆÙŠØ¨ Ø¹ÙŠÙ† Ø§Ù„ØµÙ‚Ø± ==========
with tab_falcon:
    section_header("Ø¹ÙŠÙ† Ø§Ù„ØµÙ‚Ø± â€” ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØªØ­Ø°ÙŠØ±Ø§Øª")

    # Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 Ø®Ù„Ø§Ù„ 10/15/25
    any10 = 1.0
    any15 = 1.0
    any25 = 1.0
    for b in BONUS_SEGMENTS:
        pb = p_next.get(b, 0.0)
        any10 *= (1.0 - pb)**10
        any15 *= (1.0 - pb)**15
        any25 *= (1.0 - pb)**25
    any10 = 1.0 - any10
    any15 = 1.0 - any15
    any25 = 1.0 - any25

    c0, c1, c2 = st.columns(3)
    with c0:
        st.markdown(
            f"<div style='background:#4527A0;padding:14px;border-radius:14px;font-weight:700;color:white'>"
            f"ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 10: <span style='float:right'>{pct(any10)}</span></div>",
            unsafe_allow_html=True
        )
    with c1:
        st.markdown(
            f"<div style='background:#00897B;padding:14px;border-radius:14px;font-weight:700;color:white'>"
            f"ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 15: <span style='float:right'>{pct(any15)}</span></div>",
            unsafe_allow_html=True
        )
    with c2:
        st.markdown(
            f"<div style='background:#6A1B9A;padding:14px;border-radius:14px;font-weight:700;color:white'>"
            f"ğŸ² Ø§Ø­ØªÙ…Ø§Ù„ Ø£ÙŠ Ø¨ÙˆÙ†Øµ â‰¥1 ÙÙŠ 25: <span style='float:right'>{pct(any25)}</span></div>",
            unsafe_allow_html=True
        )

    st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)

    # ØªÙ‚Ø¯ÙŠØ±Ø§Øª â‰¥Ã—50 / â‰¥Ã—100 / Ø£Ø³Ø·ÙˆØ±ÙŠ (ØªÙ‚Ø±ÙŠØ¨)
    bonus10 = {b: p_at_least_once(p_next.get(b,0.0), 10) for b in BONUS_SEGMENTS}
    p50 = sum(bonus10.values()) * 0.25
    p100 = sum(bonus10.values()) * 0.10
    pLegend = sum(bonus10.values()) * 0.04

    d1, d2, d3 = st.columns(3)
    with d1:
        st.markdown(
            f"<div style='background:#F8E16C;padding:14px;border-radius:14px;font-weight:700'>"
            f"ğŸ Ø¨ÙˆÙ†Øµ â‰¥ Ã—50 ÙÙŠ 10: <span style='float:right'>{pct(p50)}</span></div>",
            unsafe_allow_html=True
        )
    with d2:
        st.markdown(
            f"<div style='background:#1E88E5;padding:14px;border-radius:14px;font-weight:700;color:white'>"
            f"ğŸ’ Ø¨ÙˆÙ†Øµ â‰¥ Ã—100 ÙÙŠ 10: <span style='float:right'>{pct(p100)}</span></div>",
            unsafe_allow_html=True
        )
    with d3:
        st.markdown(
            f"<div style='background:#7C4DFF;padding:14px;border-radius:14px;font-weight:700;color:white'>"
            f"ğŸš€ Ø¨ÙˆÙ†Øµ Ø£Ø³Ø·ÙˆØ±ÙŠ (+100) ÙÙŠ 10: <span style='float:right'>{pct(pLegend)}</span></div>",
            unsafe_allow_html=True
        )

    # Ø£ØµÙˆØ§Øª Ø¹Ù†Ø¯ ØªØ®Ø·ÙŠ Ø§Ù„Ø¹ØªØ¨Ø§Øª
    if p100 >= 0.10:
        play_beep()
    st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)

    # ØªØºÙŠÙ‘ÙØ± Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ (Variance Ù…Ø¤Ø´Ø± ØªÙ‚Ù„Ø¨)
    Wmini = min(30, len(df))
    if Wmini >= 10:
        tail = df.tail(Wmini)
        counts = tail["segment"].value_counts(normalize=True)
        meanp = counts.mean()
        varp = ((counts - meanp)**2).mean()
        if varp > 0.005:
            change_label = "High change"; badge = "<span style='color:#D32F2F;font-weight:700'>HIGH</span>"
        elif varp > 0.002:
            change_label = "Medium change"; badge = "<span style='color:#FB8C00;font-weight:700'>MEDIUM</span>"
        else:
            change_label = "Low change"; badge = "<span style='color:#2E7D32;font-weight:700'>LOW</span>"
    else:
        change_label = "Not enough data"; badge = "<span style='color:#999'>N/A</span>"

    st.markdown(
        f"<div style='background:#1E1E1E;color:#fff;padding:14px;border-radius:12px'>"
        f"ğŸ” Ø§Ù„ØªÙ‚Ù„Ø¨ Ø§Ù„Ø¹Ø§Ù…: {change_label} â€” {badge}</div>",
        unsafe_allow_html=True
    )

    st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)

    # ØªØ­Ø°ÙŠØ±: Ø³ÙŠØ·Ø±Ø© Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø±Ù‚Ù… 1 Ø®Ù„Ø§Ù„ 15
    p1_next = p_next.get("1", 0.0)
    p1_in15 = p_at_least_once(p1_next, 15)
    high_risk_15 = p1_in15 > 0.85
    color15 = "#D32F2F" if high_risk_15 else "#37474F"
    st.markdown(
        f"<div style='background:{color15};color:#fff;padding:14px;border-radius:12px'>"
        f"âš ï¸ ØªØ­Ø°ÙŠØ±: Ø³ÙŠØ·Ø±Ø© Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø±Ù‚Ù… 1 Ø®Ù„Ø§Ù„ 15 Ø³Ø¨ÙÙ† â€” P(â‰¥1 Ø®Ù„Ø§Ù„ 15) = {pct(p1_in15)}</div>",
        unsafe_allow_html=True
    )

    # NEW: ØªØ­Ø°ÙŠØ± Ø£Ø­Ù…Ø± Ø¥Ø°Ø§ Ø§Ø­ØªÙ…Ø§Ù„ ØªÙƒØ±Ø§Ø± '1' â‰¥ 3 Ù…Ø±Ø§Øª ÙÙŠ 10 Ø±Ù…ÙŠØ§Øª
    def binom_tail_ge_k(n, p, k):
        p = max(0.0, min(1.0, float(p)))
        total = 0.0
        for r in range(0, k):  # sum P[X = 0..k-1]
            total += math.comb(n, r) * (p**r) * ((1-p)**(n-r))
        return 1.0 - total

    p1_ge3_in10 = binom_tail_ge_k(10, p1_next, 3)
    color_ge3 = "#B71C1C"  # Ø£Ø­Ù…Ø± Ø¯Ø§ÙƒÙ†
    st.markdown(
        f"<div style='background:{color_ge3};color:#fff;padding:14px;border-radius:12px'>"
        f"ğŸ›‘ ØªÙ†Ø¨ÙŠÙ‡ Ø­Ø§Ø¯: Ø§Ø­ØªÙ…Ø§Ù„ Ø£Ù† ÙŠØªÙƒØ±Ø± Ø§Ù„Ø±Ù‚Ù… <b>1</b> Ø«Ù„Ø§Ø« Ù…Ø±Ø§Øª Ø£Ùˆ Ø£ÙƒØ«Ø± Ø®Ù„Ø§Ù„ 10 Ø³Ø¨ÙÙ† = "
        f"<b>{pct(p1_ge3_in10)}</b> â€” ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ù…Ø¤Ù‚Øª.</div>",
        unsafe_allow_html=True
    )
    if p1_ge3_in10 >= 0.70:
        play_beep()

# ========== Ø£Ø³ÙÙ„ Ø§Ù„ØµÙØ­Ø© ==========
with st.expander("ğŸ“„ Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¢Ø®Ø± Ù†Ø§ÙØ°Ø©)"):
    st.dataframe(df.tail(80), use_container_width=True)

# ---------- ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø¯Ø§Ø®Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ù…Ø­Ù…Ù‘Ù„Ø© df) ----------
import pickle

with st.sidebar:
    st.markdown("---")
    st.subheader("ğŸ§ª ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")

    # Ù…ÙƒØ§Ù† Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
    model_path_input = st.text_input("Ù…Ø³Ø§Ø± Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", value="models/pattern_model.pkl", key="model_save_path")

    # Ø¹Ø±Ø¶ Ù„Ù…Ø­Ø© Ø³Ø±ÙŠØ¹Ø© Ø¹Ù† Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    with st.expander("Ù…Ù„Ø®Øµ Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"):
        st.write(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ù…ÙŠØ§Øª ÙÙŠ Ø§Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: **{len(df)}**")
        st.write("Ø£Ø¹Ù…Ø¯Ø©:", list(df.columns))
        st.dataframe(df.tail(10), use_container_width=True)

    def train_and_save_model(df, path, horizon, temperature, decay_half_life, bonus_boost):
        # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ù†ÙØ³ Ø§Ù„Ø¯Ø§Ù„Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªØ·Ø§Ø¨Ù‚
        pnext, _ = recency_softmax_probs(
            df,
            horizon=horizon,
            temperature=temperature,
            decay_half_life=decay_half_life,
            bonus_boost=bonus_boost,
        )
        model = {
            "type": "recency_softmax",
            "p_next": pnext,
            "meta": {
                "horizon": horizon,
                "temperature": temperature,
                "half_life": decay_half_life,
                "bonus_boost": bonus_boost,
                "trained_on_rows": int(len(df)),
                "trained_at": datetime.utcnow().isoformat() + "Z",
            },
        }
        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, "wb") as f:
            pickle.dump(model, f)
        return model

    if st.button("ğŸ’¾ Ø¯Ø±Ù‘ÙØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¢Ù†", use_container_width=True):
        if df.empty:
            st.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨.")
        else:
            try:
                model_obj = train_and_save_model(
                    df,
                    model_path_input,
                    horizon=horizon,
                    temperature=temperature,
                    decay_half_life=decay_half_life,
                    bonus_boost=bonus_boost,
                )
                st.success(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {model_path_input}")
                with open(model_path_input, "rb") as fh:
                    st.download_button(
                        label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬",
                        data=fh.read(),
                        file_name=os.path.basename(model_path_input),
                        mime="application/octet-stream",
                        use_container_width=True,
                    )
            except Exception as e:
                st.error(f"ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")

    st.caption("Ù†ØµÙŠØ­Ø©: Ø¨Ø¹Ø¯ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ø±ÙØ¹Ù‡ Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ models/ ÙÙŠ GitHub Ù„ÙŠØ¨Ù‚Ù‰ Ø¯Ø§Ø¦Ù…Ù‹Ø§.")
