# -*- coding: utf-8 -*-
import io
import math
import time
from datetime import datetime

import numpy as np
import pandas as pd
import streamlit as st

# --------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
# --------------------------
st.set_page_config(page_title="Funky Brain LIVE", layout="wide")
st.title("ğŸ§ ğŸ¡ Funky Brain â€“ LIVE")

# --------------------------
# Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø©
# --------------------------
TILE_ORDER = [
    "1", "BAR",
    "P", "L", "A", "Y",
    "F", "U", "N", "K",
    "VIP", "DISCO", "STAYINALIVE"
]

GROUP_MAP = {
    # Ù…ÙØ§ØªÙŠØ­ Ø£Ø­Ø±Ù/Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª Ø¥Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„ØªØ¬Ù…ÙŠØ¹
    "1": "One",
    "BAR": "BAR",
    "P": "Orange (PLAY)",
    "L": "Orange (PLAY)",
    "A": "Orange (PLAY)",
    "Y": "Orange (PLAY)",
    "F": "Pink (FUNK)",
    "U": "Pink (FUNK)",
    "N": "Pink (FUNK)",
    "K": "Pink (FUNK)",
    "VIP": "VIP",
    "DISCO": "DISCO",
    "STAYINALIVE": "STAYINALIVE",
}

DISPLAY_NAME = {
    "1": "1",
    "BAR": "BAR",
    "P": "P",
    "L": "L",
    "A": "A",
    "Y": "Y",
    "F": "F",
    "U": "U",
    "N": "N",
    "K": "K",
    "VIP": "VIP",
    "DISCO": "Disco",
    "STAYINALIVE": "Stayinâ€™ Alive",
}

def nice_percent(x, digits=2):
    return f"{x*100:.{digits}f}%"

def expected_in_n(p, n):
    # Ø§Ù„ØªÙˆÙ‚Ø¹ = n*p
    return n * p

def prob_at_least_one(p, n):
    # P(â‰¥1) = 1 - (1-p)^n
    return 1 - (1 - p) ** n

def style_table(df, header_color="#222", header_font="#fff"):
    return (
        df.style
        .format(precision=2)
        .set_table_styles(
            [
                {"selector": "thead th",
                 "props": [("background-color", header_color),
                           ("color", header_font),
                           ("font-weight", "600"),
                           ("text-align", "center")]},
                {"selector": "tbody td",
                 "props": [("text-align", "center")]}
            ]
        )
        .hide(axis="index")
    )

# --------------------------
# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
# --------------------------
st.sidebar.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")

# Ù†Ø§ÙØ°Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Ø¹Ø¯Ø¯ Ø§Ù„Ù„ÙØ§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø©)
window = st.sidebar.slider("Window size (spins)", 50, 200, 120, step=10)

# ØªØ­Ø¯ÙŠØ« ØªÙ„Ù‚Ø§Ø¦ÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
auto = st.sidebar.checkbox("Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")
every = st.sidebar.slider("ÙƒÙ„ ÙƒÙ… Ø«Ø§Ù†ÙŠØ©ØŸ", 10, 120, 45, step=5) if auto else None

# Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
st.sidebar.subheader("Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
src = st.sidebar.radio(
    "Ø§Ø®ØªØ± Ø§Ù„Ù…ØµØ¯Ø±",
    ["Ø±ÙØ¹ Ù…Ù„Ù Excel/CSV", "Ø±Ø§Ø¨Ø· Google Sheets (CSV)"],
    horizontal=False
)

uploaded = None
gsheet_csv_url = None

if src == "Ø±ÙØ¹ Ù…Ù„Ù Excel/CSV":
    uploaded = st.sidebar.file_uploader(
        "Ø§Ø®ØªØ± Ù…Ù„ÙÙ‹Ø§ (Excel .xlsx Ø£Ùˆ CSV)",
        type=["xlsx", "csv"]
    )
else:
    gsheet_csv_url = st.sidebar.text_input(
        "Ø¶Ø¹ Ø±Ø§Ø¨Ø· CSV Ù…Ù† Google Sheets (Ù…Ù„Ù > Ù…Ø´Ø§Ø±ÙƒØ© > Ù†Ø´Ø± Ù„Ù„ÙˆÙŠØ¨ > CSV)",
        value=""
    )

# Ø§Ø³Ù… Ø§Ù„ÙˆØ±Ù‚Ø© Ø¯Ø§Ø®Ù„ Excel (Ø¥Ù† ÙˆÙØ¬Ø¯)
sheet_name = st.sidebar.text_input("Ø§Ø³Ù… Ø§Ù„ÙˆØ±Ù‚Ø© (Excel ÙÙ‚Ø·)", value="sample_spins")

# --------------------------
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# --------------------------
@st.cache_data(show_spinner=False)
def load_data_from_excel(file_bytes: bytes, sheet: str):
    try:
        # Ù„Ùˆ CSV
        try:
            df = pd.read_csv(io.BytesIO(file_bytes))
            return df
        except Exception:
            pass
        # Excel
        df = pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet)
        return df
    except Exception as e:
        raise RuntimeError(f"ØªØ¹Ø°Ù‘Ø± Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")

@st.cache_data(show_spinner=False)
def load_data_from_csv_url(url: str):
    try:
        df = pd.read_csv(url)
        return df
    except Exception as e:
        raise RuntimeError(f"ØªØ¹Ø°Ù‘Ø± ØªØ­Ù…ÙŠÙ„ CSV Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·: {e}")

def validate_columns(df: pd.DataFrame):
    needed = {"ts", "segment", "multiplier"}
    missing = [c for c in needed if c not in df.columns]
    if missing:
        raise RuntimeError(f"Ø£Ø¹Ù…Ø¯Ø© Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„: {', '.join(missing)}")

def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ¶Ø¨Ø· Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ ÙˆØªØ±Ù…ÙŠØ² Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª."""
    out = df.copy()
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø·Ø§Ø¨Ø¹ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø¥Ù† ÙƒØ§Ù† Ù†ØµÙ‹Ø§
    if "ts" in out.columns:
        with pd.option_context("mode.chained_assignment", None):
            out["ts"] = pd.to_datetime(out["ts"], errors="coerce")

    # ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª (segment)
    # Ù†Ù‚Ø¨Ù„ Ø£Ø­Ø±Ù ØµØºÙŠØ±Ø©/ÙƒØ¨ÙŠØ±Ø© ÙˆØ¨Ø¹Ø¶ Ø§Ù„ØµÙŠØº Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
    repl = {
        "stayinalive": "STAYINALIVE",
        "stayinalive ": "STAYINALIVE",
        "disco": "DISCO",
        "vip": "VIP",
        "bar": "BAR",
        "p": "P", "l": "L", "a": "A", "y": "Y",
        "f": "F", "u": "U", "n": "N", "k": "K",
        "1": "1"
    }
    with pd.option_context("mode.chained_assignment", None):
        out["segment"] = out["segment"].astype(str).str.strip()
        out["segment"] = out["segment"].str.upper().replace(repl)

        # Ø§Ù„Ù…Ø¶Ø§Ø¹Ù: Ù†Ø­Ø°Ù X Ø¥Ù† ÙˆÙØ¬Ø¯ (Ù…Ø«Ù„ 25X)
        out["multiplier"] = (
            out["multiplier"].astype(str).str.upper().str.replace("X", "", regex=False)
        )
        # Ø£ÙŠ Ù‚ÙŠÙ…Ø© ØºÙŠØ± Ø¹Ø¯Ø¯ÙŠØ© Ù†Ø¬Ø¹Ù„Ù‡Ø§ NaN Ø«Ù… Ù†Ø­ÙˆÙ„ Ø¥Ù„Ù‰ float
        out["multiplier"] = pd.to_numeric(out["multiplier"], errors="coerce")

    # Ø¥Ø¨Ù‚Ø§Ø¡ Ø§Ù„ØµÙÙˆÙ Ø°Ø§Øª Ù‚Ø·Ø§Ø¹ Ù…Ø¹Ø±ÙˆÙ ÙÙ‚Ø·
    out = out[out["segment"].isin(TILE_ORDER)]
    out = out.sort_values("ts", ascending=True).reset_index(drop=True)
    return out

def compute_tiles_table(df: pd.DataFrame, win: int) -> pd.DataFrame:
    """ÙŠØ¨Ù†ÙŠ Ø¬Ø¯ÙˆÙ„ Tiles: Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙˆÙÙ‚ Ø¢Ø®Ø± Ù†Ø§ÙØ°Ø©."""
    if len(df) == 0:
        return pd.DataFrame(columns=["Title", "Group", "P(next)", "Exp in 10", "P(â‰¥1 in 10)", "Exp in 15", "P(â‰¥1 in 15)"])

    # Ø¢Ø®Ø± Ù†Ø§ÙØ°Ø©
    wdf = df.tail(win)
    total = len(wdf)

    rows = []
    for key in TILE_ORDER:
        cnt = (wdf["segment"] == key).sum()
        p = cnt / total if total > 0 else 0.0
        row = {
            "Title": DISPLAY_NAME.get(key, key),
            "Group": GROUP_MAP.get(key, "â€”"),
            "P(next)": p,
            "Exp in 10": expected_in_n(p, 10),
            "P(â‰¥1 in 10)": prob_at_least_one(p, 10),
            "Exp in 15": expected_in_n(p, 15),
            "P(â‰¥1 in 15)": prob_at_least_one(p, 15),
        }
        rows.append(row)

    tdf = pd.DataFrame(rows)

    # ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ø¹Ø±Ø¶
    show = tdf.copy()
    show["P(next)"] = show["P(next)"].apply(nice_percent)
    show["Exp in 10"] = show["Exp in 10"].map(lambda x: f"{x:.1f}")
    show["P(â‰¥1 in 10)"] = show["P(â‰¥1 in 10)"].apply(nice_percent)
    show["Exp in 15"] = show["Exp in 15"].map(lambda x: f"{x:.1f}")
    show["P(â‰¥1 in 15)"] = show["P(â‰¥1 in 15)"].apply(nice_percent)

    return show

# --------------------------
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ù…Ø®ØªØ§Ø±
# --------------------------
df_raw = None
load_err = None

if src == "Ø±ÙØ¹ Ù…Ù„Ù Excel/CSV":
    if uploaded is not None:
        try:
            df_raw = load_data_from_excel(uploaded.getvalue(), sheet_name)
        except Exception as e:
            load_err = str(e)
else:
    if gsheet_csv_url:
        try:
            df_raw = load_data_from_csv_url(gsheet_csv_url)
        except Exception as e:
            load_err = str(e)

if load_err:
    st.error(load_err)

if df_raw is None:
    st.info("â¬†ï¸ Ø§Ø±ÙØ¹ Ù…Ù„ÙÙƒ (Ø£Ùˆ Ø¶Ø¹ Ø±Ø§Ø¨Ø· CSV Ù…Ù† Google Sheets) Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„.\n\n"
            "ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: **ts**, **segment**, **multiplier**.")
    st.stop()

# ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
try:
    validate_columns(df_raw)
except Exception as e:
    st.error(str(e))
    st.stop()

# ØªÙ†Ø¸ÙŠÙ ÙˆØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
df = normalize_df(df_raw)

# --------------------------
# Ø¹Ø±Ø¶ Ø¬Ø¯Ø§ÙˆÙ„/Ù…Ù„Ø®Øµ
# --------------------------
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("Tiles â€“ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª ÙˆØªÙˆÙ‚Ø¹Ø§Øª")
    tiles_df = compute_tiles_table(df, window)
    st.dataframe(style_table(tiles_df, header_color="#101828"), use_container_width=True)

with col2:
    st.subheader("Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ø§ÙØ°Ø©")
    wdf = df.tail(window).copy()
    total = len(wdf)
    by_group = (
        wdf.assign(Group=wdf["segment"].map(GROUP_MAP))
           .groupby("Group", dropna=False)["segment"]
           .count()
           .rename("count")
           .sort_values(ascending=False)
    )
    summary = pd.DataFrame({
        "Ù†Ø§ÙØ°Ø©": [window],
        "Ø¹Ø¯Ø¯ Ø§Ù„Ù„ÙØ§Øª (Ù†Ø§ÙØ°Ø©)": [total],
        "Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«": [datetime.now().strftime("%Y-%m-%d %H:%M:%S")]
    })
    st.dataframe(style_table(summary, header_color="#512DA8"), use_container_width=True)

    st.write("**Ø§Ù„Ø¹Ø¯Ù‘ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© (Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Ø§ÙØ°Ø©):**")
    grp_df = by_group.reset_index()
    st.dataframe(style_table(grp_df, header_color="#512DA8"), use_container_width=True)

# Ø³Ø¬Ù„Ù‘ Ø¢Ø®Ø± Ø§Ù„Ù„ÙØ§Øª (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)
st.subheader("Ø¢Ø®Ø± Ø§Ù„Ù„ÙØ§Øª (raw)")
tail_show = df.tail(min(200, len(df))).copy()
tail_show["multiplier"] = tail_show["multiplier"].map(lambda x: f"{x:.0f}X" if pd.notnull(x) else "")
st.dataframe(style_table(tail_show, header_color="#0B7285"), use_container_width=True)

# Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
if auto and every:
    st.caption(f"Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ **{every}** Ø«Ø§Ù†ÙŠØ©.")
    # Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ø¥Ø¬Ø¨Ø§Ø± Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ø¯ÙˆÙ† Ø­Ø²Ù… Ø¥Ø¶Ø§ÙÙŠØ©:
    time.sleep(every)
    st.experimental_rerun()
